<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 2 Cross-validation | [ENAR 2023 Short Course] Targeted Learning in the tlverse</title>
<meta name="author" content="Mark van der Laan, Alan Hubbard, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips">
<meta name="description" content="Ivana Malenica Based on the origami R package by Jeremy Coyle, Nima Hejazi, Ivana Malenica and Rachael Phillips. Learning Objectives By the end of this chapter you will be able to: Differentiate...">
<meta name="generator" content="bookdown 0.32.2 with bs4_book()">
<meta property="og:title" content="Chapter 2 Cross-validation | [ENAR 2023 Short Course] Targeted Learning in the tlverse">
<meta property="og:type" content="book">
<meta property="og:url" content="https://tlverse.org/enar2023-workshop/origami.html">
<meta property="og:description" content="Ivana Malenica Based on the origami R package by Jeremy Coyle, Nima Hejazi, Ivana Malenica and Rachael Phillips. Learning Objectives By the end of this chapter you will be able to: Differentiate...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 2 Cross-validation | [ENAR 2023 Short Course] Targeted Learning in the tlverse">
<meta name="twitter:description" content="Ivana Malenica Based on the origami R package by Jeremy Coyle, Nima Hejazi, Ivana Malenica and Rachael Phillips. Learning Objectives By the end of this chapter you will be able to: Differentiate...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.2/transition.js"></script><script src="libs/bs3compat-0.4.2/tabs.js"></script><script src="libs/bs3compat-0.4.2/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script><script src="libs/htmlwidgets-1.6.1/htmlwidgets.js"></script><link href="libs/vis-9.1.0/vis-network.min.css" rel="stylesheet">
<script src="libs/vis-9.1.0/vis-network.min.js"></script><script src="libs/visNetwork-binding-2.1.2/visNetwork.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
</head>
<body>
<span class="math inline">
  \(\DeclareMathOperator{\expit}{expit}\)
  \(\DeclareMathOperator{\logit}{logit}\)
  \(\DeclareMathOperator*{\argmin}{\arg\!\min}\)
  \(\newcommand{\indep}{\perp\!\!\!\perp}\)
  \(\newcommand{\coloneqq}{\mathrel{=}}\)
  \(\newcommand{\R}{\mathbb{R}}\)
  \(\newcommand{\E}{\mathbb{E}}\)
  \(\newcommand{\M}{\mathcal{M}}\)
  \(\renewcommand{\P}{\mathbb{P}}\)
  \(\newcommand{\I}{\mathbb{I}}\)
  \(\newcommand{\1}{\mathbbm{1}}\)
  </span>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Advanced Methods for Causal Machine Learning">[ENAR 2023 Short Course] Targeted Learning in the <code>tlverse</code></a>:
        <small class="text-muted">Advanced Methods for Causal Machine Learning</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome!</a></li>
<li><a class="" href="introduction.html">Introduction</a></li>
<li class="book-part">Part 1: Preliminaries</li>
<li><a class="" href="setting-up-r-and-rstudio.html">Setting up R and RStudio</a></li>
<li><a class="" href="install-tlverse-software-installtlverse.html">Install tlverse software {#installtlverse}</a></li>
<li><a class="" href="supplemental-learning-resources.html">Supplemental learning resources</a></li>
<li class="book-part">Part 2: The tlverse</li>
<li><a class="" href="what-is-the-tlverse.html">What is the tlverse?</a></li>
<li><a class="" href="primer-on-the-r6-class-system.html">Primer on the R6 Class System</a></li>
<li class="book-part">Part 3: Foundations</li>
<li><a class="" href="intro.html"><span class="header-section-number">1</span> The Roadmap for Targeted Learning</a></li>
<li><a class="" href="example-dataset.html">Example Dataset</a></li>
<li><a class="active" href="origami.html"><span class="header-section-number">2</span> Cross-validation</a></li>
<li><a class="" href="sl3.html"><span class="header-section-number">3</span> Super Learning</a></li>
<li><a class="" href="tmle3.html"><span class="header-section-number">4</span> The TMLE Framework</a></li>
<li class="book-part">Part 4: Advanced Topics</li>
<li><a class="" href="optimal-individualized-treatment-regimes.html"><span class="header-section-number">5</span> Optimal Individualized Treatment Regimes</a></li>
<li><a class="" href="stochastic-treatment-regimes.html"><span class="header-section-number">6</span> Stochastic Treatment Regimes</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/tlverse/enar2023-workshop">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="origami" class="section level1">
<h1>
<span class="header-section-number">2</span> Cross-validation<a class="anchor" aria-label="anchor" href="#origami"><i class="fas fa-link"></i></a>
</h1>
<p><em>Ivana Malenica</em></p>
<p>Based on the <a href="https://github.com/tlverse/origami"><code>origami</code> <code>R</code> package</a>
by <em>Jeremy Coyle, Nima Hejazi, Ivana Malenica and Rachael Phillips</em>.</p>
<div id="learning-objectives-1" class="section level2 unnumbered">
<h2>Learning Objectives<a class="anchor" aria-label="anchor" href="#learning-objectives-1"><i class="fas fa-link"></i></a>
</h2>
<p>By the end of this chapter you will be able to:</p>
<ol style="list-style-type: decimal">
<li><p>Differentiate between training, validation and test sets.</p></li>
<li><p>Understand the concept of a loss function, risk and cross-validation.</p></li>
<li><p>Select a loss function that is appropriate for the functional parameter to be
estimated.</p></li>
<li><p>Understand and contrast different cross-validation schemes for i.i.d. data.</p></li>
<li><p>Understand and contrast different cross-validation schemes for time dependent
data.</p></li>
<li><p>Setup the proper fold structure, build custom fold-based function, and
cross-validate the proposed function using the <code>origami</code> <code>R</code> package.</p></li>
<li><p>Setup the proper cross-validation structure for the use by the Super Learner
using the the <code>origami</code> <code>R</code> package.</p></li>
</ol>
<!--
RP: 
suggestion to modify some LOs (I am also open to not having LOs).
LOs should be expressed in terms of the reader and use action verbs. 
Some ideas for action verbs related to "understanding" are here, within
"Action Verbs Aligned with Blooms Taxonomy" section:
https://academiceffectiveness.gatech.edu/assessment-toolkit/developing-student-learning-outcome-statements
Here's another helpful article:
https://www.thoughtco.com/common-mistakes-when-writing-learning-objectives-7786

As an example, for LO 2, it can be rephrased by thinking about the answers to 
these questions and targeting the LO towards them. 
What specifically does a reader need to understand about a loss, risk, CV? 
Why is this important for the reader to understand?
-->
</div>
<div id="introduction-2" class="section level2">
<h2>
<span class="header-section-number">2.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-2"><i class="fas fa-link"></i></a>
</h2>
<p>In this chapter, we elaborate on the estimation step outlined in the chapter on
the <a href="#roadmap"><em>Roadmap for Targeted Learning</em></a>. In order to generate an
estimate of the target parameter, we need to decide how to evaluate the quality
of our estimation procedure’s performance.
The performance, or error, of any algorithm/estimator corresponds to its
generalizability to independent datasets arising from the same data-generating
process. The assessment of the performance of an algorithm is extremely
important — it provides a quantitative assessment of how well the
algorithm performs, and it guides the choice of the selecting among a set
(or “library”) of algorithms. In order to assess the performance of
an algorithm, or a library of them, we introduce the concept of a
<strong>loss function</strong>, which defines the <strong>risk</strong> or the <strong>expected prediction error</strong>.<br>
Our goal, as further detailed in the next chapter, will be to estimate the
performance of a library of algorithms in order to choose the best-performing
one. In the following, we propose a method to do so using the observed data and
<strong>cross-validation</strong> procedures implemented in the <code>origami</code> package
<span class="citation">(Coyle and Hejazi <a href="references.html#ref-coyle2018origami" role="doc-biblioref">2018</a>; Coyle et al., <a href="references.html#ref-coyle-cran-origami" role="doc-biblioref">n.d.</a>)</span>.
<!--
RP:
The text before read:

Our goal, as further detailed in the next chapter, will be to estimate the true
risk of the proposed statistical learning method. Our goal(s) consist of:
1. Estimating the performance of different learning algorithms in order to
   choose the best one for the problem at hand.
2. Having chosen a winning algorithm, estimate the true risk of the proposed
   statistical learning method.
   
In "true risk of the proposed statistical learning method", what is meant by 
"proposed statistical learning method"? 
In doing step 1, we are doing step 2. The algorithms' performance estimates are 
estimates of the true risk, ie when we estimate the performance of different 
learning algorithms we are estimating the true risk. 
--></p>
</div>
<div id="background" class="section level2">
<h2>
<span class="header-section-number">2.2</span> Background<a class="anchor" aria-label="anchor" href="#background"><i class="fas fa-link"></i></a>
</h2>
<p>Ideally, in a data-rich scenario (i.e., one with unlimited observations), we would
split our dataset into three parts:</p>
<ol style="list-style-type: decimal">
<li>the training set,</li>
<li>the validation set, and</li>
<li>the test (or holdout) set.</li>
</ol>
<p>The training set is used to fit algorithm(s) of interest; we evaluate the
performance of the fit(s) on a validation set, which can be used to estimate
prediction error (e.g., for algorithm tuning or selection). The final error of the
selected algorithm is obtained by using the test (or holdout) set, which is
kept entirely separate such that the algorithms never encounter these
observations until the final model evaluation step. One might wonder, with
training data readily available, why not use the training error to evaluate the
proposed algorithm’s performance? Unfortunately, the training error is a biased
estimate of a fitted algorithm’s generalizability, since it uses the same data
for fitting and evaluation.</p>
<!--
RP:
if we want to introduce "true risk" then it needs to be defined. I am not 
sure if this explanation requires the notion of "true risk" in order to 
understand that the training error is a poor evaluation of a fitted 
algorithm's generalizability 
also, we say "model complexity", but don't explain what that is. I don't think 
the reader will know what this means / it will mean something different to 
different readers if we don't define what we mean by this.
-->
<p>Since data are often scarce, separating a dataset into training, validation and
test sets can prove too limiting, on account of decreasing the available data
for use in training by too much. In the absence of a large dataset and a
designated test set, we must resort to methods that estimate the true risk by
efficient sample re-use. Re-sampling methods, like the bootstrap, involve
repeatedly sampling from the training set and fitting the
algorithms to these samples. While often computationally
intensive, re-sampling methods are particularly useful for evaluating an
algorithm and selecting among a set of them. In addition, they provide
more insight on the variability and robustness of a fitted algorithm, relative
to fitting an algorithm only once to all of the training data.</p>
<!--
RP:
What is meant by "scarce", "by too much", "large dataset" here? We also might 
want to use CV even when we have thousands of observations, so our assessment of
the algorithm isn't hinging on a single split. Is the data's size the motivating 
reason for re-sampling? 
Ah-ha! I knew you had it somewhere! I think the (some of) message that you're 
getting across in the paragraph around L380 should be included here. 
-->
<div id="introducing-cross-validation" class="section level3">
<h3>
<span class="header-section-number">2.2.1</span> Introducing: cross-validation<a class="anchor" aria-label="anchor" href="#introducing-cross-validation"><i class="fas fa-link"></i></a>
</h3>
<p>In this chapter, we focus on <strong>cross-validation</strong> — an essential tool for
evaluating how any algorithm extends from a sample of data to the target
population from which it arose. Cross-validation has seen widespread
application in all facets of modern statistics, and perhaps most notably in
statistical machine learning. The cross-validation procedure has been proven to
be optimal for algorithm selection in large samples, i.e. asymptotically. In particular,
cross-validation directly estimates the true risk when the estimate is applied
to an independent sample from the joint distribution of the predictors and
outcome.
<!--
RP:
the above sentence requires clarification, cross-validation doesn't directly 
estimate anything
-->
When used for model selection, cross-validation has powerful optimality
properties. The asymptotic optimality results state that the cross-validated
selector performs (in terms of risk) asymptotically as well as an optimal oracle
selector, a hypothetical procedure with free access to the true, unknown
data-generating distribution. For further details on the theoretical results, we
suggest consulting <span class="citation">van der Laan and Dudoit (<a href="references.html#ref-vdl2003unified" role="doc-biblioref">2003</a>)</span>, <span class="citation">van der Laan, Dudoit, and Keles (<a href="references.html#ref-vdl2004asymptotic" role="doc-biblioref">2004</a>)</span>, <span class="citation">Dudoit and van der Laan (<a href="references.html#ref-dudoit2005asymptotics" role="doc-biblioref">2005</a>)</span>
and <span class="citation">van der Vaart, Dudoit, and van der Laan (<a href="references.html#ref-vaart2006oracle" role="doc-biblioref">2006</a>)</span>.</p>
<p>Cross-validation works by partitioning a sample into complementary subsets: a
training (sub)set, to which a particular learning algorithm is applied, and a
complementary validation (sub)set, used to evaluate the given algorithm’s
learning performance.
<!--
RP:
we introduced training and validation above, so maybe we don't need to redefine 
here. Also, if we have a test set or use re-sampling like bootstrap then the 
training and validation are not complementary. I think only in V fold (with no 
test set) are they complementary?
-->
By repeating this general procedure across multiple
partitions of the dataset, the average risk (over the partitions of the data)
can be computed without allowing data to leak between training and validation
subsets. A variety of different partitioning schemes exist, each tailored to the
salient details of the problem of interest, including data size, prevalence of
the outcome, and dependence structure (between units or across time).
<!--
RP:
this paragraph (not including what is below) is difficult to understand unless 
you have already have a solid understanding of CV. I say we try to omit it or 
clarify. We delve into this in the later sections so I think saving this 
explanation for later is OK
-->
The <code>origami</code> package
provides a suite of tools for cross-validation. In the following, we describe different
types of cross-validation schemes readily available in <code>origami</code>, introduce the
general structure of the <code>origami</code> package, and demonstrate the use of these
procedures in applied settings.
—</p>
</div>
</div>
<div id="estimation-roadmap-how-does-it-all-fit-together" class="section level2">
<h2>
<span class="header-section-number">2.3</span> Estimation Roadmap: How does it all fit together?<a class="anchor" aria-label="anchor" href="#estimation-roadmap-how-does-it-all-fit-together"><i class="fas fa-link"></i></a>
</h2>
<p>Similarly to how we defined the <a href="#roadmap"><em>Roadmap for Targeted Learning</em></a>, we
can define the <strong>Estimation Roadmap</strong> as a guide for the estimation process. In
particular, the unified loss-based estimation framework <span class="citation">(van der Laan and Dudoit <a href="references.html#ref-vdl2003unified" role="doc-biblioref">2003</a>; van der Laan, Dudoit, and Keles <a href="references.html#ref-vdl2004asymptotic" role="doc-biblioref">2004</a>; Dudoit and van der Laan <a href="references.html#ref-dudoit2005asymptotics" role="doc-biblioref">2005</a>; van der Vaart, Dudoit, and van der Laan <a href="references.html#ref-vaart2006oracle" role="doc-biblioref">2006</a>; van der Laan, Polley, and Hubbard <a href="references.html#ref-vdl2007super" role="doc-biblioref">2007</a>)</span>,
which relies on cross-validation for estimator construction,
selection, and performance assessment, consists of three main steps:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Loss function</strong>:
Define the target parameter as the minimizer of the expected loss (risk) for a
complete data loss function chosen to represent the desired performance measure.
Map the complete data loss function into an observed data loss function, having
the same expected value and leading to an efficient estimator of risk.
<!--
RP:
what is meant by "complete data loss function"? Do we need this 
"leading to an efficient estimator of risk"? We haven't defined what an efficient 
estimator of the risk is, so maybe we can avoid introducing that? 
--></p></li>
<li><p><strong>Algorithms</strong>:
Construct a finite collection of candidate estimators of the parameter of
interest.</p></li>
<li><p><strong>Cross-validation scheme</strong>:
Apply appropriate cross-validation to select an optimal estimator among the
candidates and assess the overall performance of the resulting estimator.
<!--
RP:
CV doesn't select the optimal estimator, the selection is determined by the 
loss function.
--></p></li>
</ol>
</div>
<div id="example-cross-validation-and-prediction" class="section level2">
<h2>
<span class="header-section-number">2.4</span> Example: Cross-validation and Prediction<a class="anchor" aria-label="anchor" href="#example-cross-validation-and-prediction"><i class="fas fa-link"></i></a>
</h2>
<p>Having introduced the <a href="#roadmap">Estimation Roadmap</a>, we can more precisely
define our objective using prediction as an example.
Let the observed data be defined as <span class="math inline">\(O = (W, Y)\)</span>, where a unit
specific data structure can be written as <span class="math inline">\(O_i = (W_i, Y_i)\)</span>, for <span class="math inline">\(i = 1, \ldots, n\)</span>.
We denote <span class="math inline">\(Y_i\)</span> as the outcome/dependent variable of interest, and <span class="math inline">\(W_i\)</span> as a
<span class="math inline">\(p\)</span>-dimensional set of covariate/predictor variables. As is standard, we assume
the <span class="math inline">\(n\)</span> units are independent, or conditionally independent, and identically
distributed. Let <span class="math inline">\(\psi_0(W)\)</span> denote the target parameter of interest, the
quantity we wish to estimate. For this example, we are interested in estimating the
conditional expectation of the outcome given the covariates, <span class="math inline">\(\psi_0(W) = \E(Y \mid W)\)</span>. Following the <a href="#roadmap">Estimation Roadmap</a>, we choose the
appropriate loss function, <span class="math inline">\(L\)</span>, such that <span class="math inline">\(\psi_0(W) = \text{argmin}_{\psi} \E_0[L(O, \psi(W))]\)</span>. But, how do we know how well each of the candidate
estimators of <span class="math inline">\(\psi_0(W)\)</span> are doing? To pick the best-performing
candidate estimator and assess its overall performance, we
use cross-validation — dividing the available data into the training sets and
validation sets. Observations in the training set are used to fit (or train) the
estimator, while those in validation set are used to assess the risk of (or
validate) it.
<!--
RP:
don't think we need to redefine what training and validation sets are 
-->
Next, we introduce notation flexible enough to represent any cross-validation
scheme. In particular, we define a <strong>split vector</strong>, <span class="math inline">\(B_n = (B_n(i): i = 1, \ldots, n) \in \{0,1\}^n\)</span>; note that such a split vector is independent of the empirical
distribution <span class="math inline">\(P_n\)</span>. A realization of <span class="math inline">\(B_n\)</span> defines a random split of the data
into training and validation subsets such that if
<!--
RP:
why is it necessary to note that the split vector is independent of P_n?
-->
<span class="math display">\[B_n(i) = 0, \ \ \text{i sample is in the training set}\]</span>
<span class="math display">\[B_n(i) = 1, \ \ \text{i sample is in the validation set.}\]</span>
We can further define <span class="math inline">\(P_{n, B_n}^0\)</span> and <span class="math inline">\(P_{n, B_n}^1\)</span> as the empirical
distributions of the training and validation sets, respectively. Then, <span class="math inline">\(n_0 = \sum_i (1 - B_n(i))\)</span> and <span class="math inline">\(n_1 = \sum_i B_n(i)\)</span> denote the number of samples in
the training and validation sets, respectively. The particular distribution
of the split vector <span class="math inline">\(B_n\)</span> defines the type of cross-validation scheme, tailored
to the problem and dataset at hand.</p>
<!--
nh: high-level comment -- it's helpful to define the splitting vector notation
with B_n and to explain it, but I think it could be made even clearer by
explicitly writing the forms of the splitting vector for each of the CV schemes
discussed below. this helps to make it concrete, since the notation is quite
general and exact but simultaneously cumbersome (a complaint I've heard in
seminars and agree with, personally -- e.g., it's much easier to write V-fold
CV in simpler notation than this). it seems it shouldn't be much work to write
examples of the splitting vector notation for the more common CV schemes, but
maybe it gets annoying for time-series examples. just a thought...
-->
</div>
<div id="cross-validation-schemes-in-origami" class="section level2">
<h2>
<span class="header-section-number">2.5</span> Cross-validation schemes in <code>origami</code><a class="anchor" aria-label="anchor" href="#cross-validation-schemes-in-origami"><i class="fas fa-link"></i></a>
</h2>
<p>In the following, we describe different
cross-validation schemes available in the <code>origami</code> package, and we go on to
demonstrate their use in practical data analysis examples.</p>
<div id="wash-benefits-study-example" class="section level3 unnumbered">
<h3>WASH Benefits Study Example<a class="anchor" aria-label="anchor" href="#wash-benefits-study-example"><i class="fas fa-link"></i></a>
</h3>
<p>In order to illustrate different cross-validation schemes, we will be using the
WASH Benefits example dataset (detailed information can be found in
<a href="#wash">Chapter 3</a>). In particular, we are interested in predicting
weight-for-height Z-score (<code>whz</code>) using the available covariate data. For this
illustration, we will start by treating the data as independent and identically
distributed (i.i.d.) random draws from an unknown distribution <span class="math inline">\(P_0\)</span>. To
see what each cross-validation scheme is doing, we will subset the data to only
<span class="math inline">\(n=30\)</span>. Note that each row represents an i.i.d. sampled unit, indexed by the row
number.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com">data.table</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tlverse.org/origami/">origami</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://yihui.org/knitr/">knitr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://haozhu233.github.io/kableExtra/">kableExtra</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># load data set and take a peek</span></span>
<span><span class="va">washb_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/fread.html">fread</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span></span>
<span>    <span class="st">"https://raw.githubusercontent.com/tlverse/tlverse-data/master/"</span>,</span>
<span>    <span class="st">"wash-benefits/washb_data.csv"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  stringsAsFactors <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
whz
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
tr
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fracode
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
month
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
aged
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
sex
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momage
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momedu
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momheight
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
hfiacat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Nlt18
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Ncomp
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
watmin
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
elec
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
floor
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
walls
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
roof
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_wardrobe
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_table
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chair
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_khat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chouki
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_tv
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_refrig
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_bike
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_moto
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_sewmach
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_mobile
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
268
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
146.40
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.16
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
286
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
148.75
</td>
<td style="text-align:left;">
Moderately Food Insecure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.05
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
264
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
152.15
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.26
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
252
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
28
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
140.25
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.59
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
336
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
150.95
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.51
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
304
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
154.20
</td>
<td style="text-align:left;">
Severely Food Insecure
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table></div>
</div>
<p>Above is a look at the first 30 of the data.</p>
</div>
<div id="cross-validation-for-i.i.d.-data" class="section level3">
<h3>
<span class="header-section-number">2.5.1</span> Cross-validation for i.i.d. data<a class="anchor" aria-label="anchor" href="#cross-validation-for-i.i.d.-data"><i class="fas fa-link"></i></a>
</h3>
<div id="re-substitution" class="section level4">
<h4>
<span class="header-section-number">2.5.1.1</span> Re-substitution<a class="anchor" aria-label="anchor" href="#re-substitution"><i class="fas fa-link"></i></a>
</h4>
<p>The re-substitution method is perhaps the simplest strategy for estimating the
risk of a fitted algorithm. With
this cross-validation scheme, all observed data units are used in both the
training and validation set.</p>
<p>We illustrate the usage of the re-substitution method with <code>origami</code> below,
using the function <code>folds_resubstitution</code>. In order to set up
<code>folds_resubstitution</code>, we need only to specify the total number of sampled
units that we want to allocate to the training and validation sets; remember
that each row of the dataset is a unique i.i.d. sampled unit. Also, notice the
structure of the <code>origami</code> output:</p>
<ol style="list-style-type: decimal">
<li>
<strong>v:</strong> the cross-validation fold</li>
<li>
<strong>training_set:</strong> the indices of the samples in the training set</li>
<li>
<strong>validation_set:</strong> the indices of the samples in the training set.</li>
</ol>
<p>The structure of the <code>origami</code> output, a <code>list</code> of fold(s), holds across all of
the cross-validation schemes presented in this chapter. Below, we show the fold
generated by the re-substitution method:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="origami.html#cb6-1"></a>folds &lt;-<span class="st"> </span><span class="kw">folds_resubstitution</span>(<span class="kw">nrow</span>(washb_data))</span>
<span id="cb6-2"><a href="origami.html#cb6-2"></a>folds</span>
<span id="cb6-3"><a href="origami.html#cb6-3"></a>[[<span class="dv">1</span>]]</span>
<span id="cb6-4"><a href="origami.html#cb6-4"></a><span class="op">$</span>v</span>
<span id="cb6-5"><a href="origami.html#cb6-5"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb6-6"><a href="origami.html#cb6-6"></a></span>
<span id="cb6-7"><a href="origami.html#cb6-7"></a><span class="op">$</span>training_set</span>
<span id="cb6-8"><a href="origami.html#cb6-8"></a> [<span class="dv">1</span>]  <span class="dv">1</span>  <span class="dv">2</span>  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">5</span>  <span class="dv">6</span>  <span class="dv">7</span>  <span class="dv">8</span>  <span class="dv">9</span> <span class="dv">10</span> <span class="dv">11</span> <span class="dv">12</span> <span class="dv">13</span> <span class="dv">14</span> <span class="dv">15</span> <span class="dv">16</span> <span class="dv">17</span> <span class="dv">18</span> <span class="dv">19</span> <span class="dv">20</span> <span class="dv">21</span> <span class="dv">22</span> <span class="dv">23</span> <span class="dv">24</span> <span class="dv">25</span></span>
<span id="cb6-9"><a href="origami.html#cb6-9"></a>[<span class="dv">26</span>] <span class="dv">26</span> <span class="dv">27</span> <span class="dv">28</span> <span class="dv">29</span> <span class="dv">30</span></span>
<span id="cb6-10"><a href="origami.html#cb6-10"></a></span>
<span id="cb6-11"><a href="origami.html#cb6-11"></a><span class="op">$</span>validation_set</span>
<span id="cb6-12"><a href="origami.html#cb6-12"></a> [<span class="dv">1</span>]  <span class="dv">1</span>  <span class="dv">2</span>  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">5</span>  <span class="dv">6</span>  <span class="dv">7</span>  <span class="dv">8</span>  <span class="dv">9</span> <span class="dv">10</span> <span class="dv">11</span> <span class="dv">12</span> <span class="dv">13</span> <span class="dv">14</span> <span class="dv">15</span> <span class="dv">16</span> <span class="dv">17</span> <span class="dv">18</span> <span class="dv">19</span> <span class="dv">20</span> <span class="dv">21</span> <span class="dv">22</span> <span class="dv">23</span> <span class="dv">24</span> <span class="dv">25</span></span>
<span id="cb6-13"><a href="origami.html#cb6-13"></a>[<span class="dv">26</span>] <span class="dv">26</span> <span class="dv">27</span> <span class="dv">28</span> <span class="dv">29</span> <span class="dv">30</span></span>
<span id="cb6-14"><a href="origami.html#cb6-14"></a></span>
<span id="cb6-15"><a href="origami.html#cb6-15"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb6-16"><a href="origami.html#cb6-16"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span></code></pre></div>
<!--
nh: should we comment briefly on the displayed structure of the training
and validation folds?
-->
</div>
<div id="holdout" class="section level4">
<h4>
<span class="header-section-number">2.5.1.2</span> Holdout<a class="anchor" aria-label="anchor" href="#holdout"><i class="fas fa-link"></i></a>
</h4>
<p>The holdout method, or the validation set approach, consists of randomly
dividing the available data into training and validation (holdout) sets. The
model is then fitted (i.e., “trained”) using the observations in the training
set and subsequently evaluated (i.e., “validated”) using the observations in the
validation set. Typically, the dataset is split into <span class="math inline">\(60:40\)</span>, <span class="math inline">\(70:30\)</span>, <span class="math inline">\(80:20\)</span>
or even <span class="math inline">\(90:10\)</span> training-to-validation splits.</p>
<p>The holdout method is intuitive and computationally inexpensive; however, it
does carry a disadvantage: If we were to repeat the process of randomly
splitting the data into training and validation sets, we could get very
different cross-validated estimates of the empirical risk. In particular, the
empirical mean of the loss function (i.e., the empirical risk) evaluated over
the validation set(s) could be highly variable, depending on which samples were
included in the training and validation splits. Overall, the cross-validated
empirical risk for the holdout method is more variable, since in includes
variability of the random split as well — this is not desirable. For
classification problems (with a binary or categorical outcome variable), there
is an additional disadvantage: it is possible for the training and validation
sets to end up with uneven distributions of the two (or more) outcome classes,
leading to better training and poor validation, or vice-versa — though this may
be corrected by incorporating stratification into the cross-validation process.
Finally, note that we are not using all of the data in training or in evaluating
the performance of the proposed algorithm, which could itself introduce bias.</p>
<!--
nh: is there no folds_* function for this in origami? it seems to be the only
cross-validation scheme for which we don't demonstrate fold construction
-->
</div>
<div id="leave-one-out" class="section level4">
<h4>
<span class="header-section-number">2.5.1.3</span> Leave-one-out<a class="anchor" aria-label="anchor" href="#leave-one-out"><i class="fas fa-link"></i></a>
</h4>
<p>The leave-one-out cross-validation scheme is closely related to the holdout
method, as it also involves splitting the dataset into training and validation
sets; however, instead of partitioning the dataset into sets of similar size, a
single observation is used as the validation set. In doing so, the vast majority
of the sampled units are employed for fitting (or training) the candidate
learning algorithm. Since only a single sampled unit (for example <span class="math inline">\(O_1 = (W_1, Y_1)\)</span>) is left out of the fitting process, leave-one-out cross-validation can
result in a less biased estimate of the risk. Typically, the
leave-one-out approach will not overestimate the risk as much as the holdout
method does. On the other hand, since the estimate of risk is based on a single
sampled unit, it is usually a highly variable estimate.</p>
<p>We can repeat the process of spiting the dataset into training and validation
sets until all of the sampled units have had a chance to act as the validation
set. Continuing the example above, a subsequent iteration of the leave-one-out
cross-validation scheme may use <span class="math inline">\(O_2 = (W_2, Y_2)\)</span> as the validation set (where,
before, <span class="math inline">\(O_1 = (W_1, Y_1)\)</span> played that role), while the remaining <span class="math inline">\(n-1\)</span> sampled
units are included in the training set. Repeating this approach <span class="math inline">\(n\)</span> times
results in <span class="math inline">\(n\)</span> risk estimates, for example, <span class="math inline">\(MSE_1, MSE_2, \ldots, MSE_n\)</span> (note
that these are the mean squared error (MSE) estimates when unit <span class="math inline">\(i\)</span> is the
validation set). The estimate of the true risk is then the average over the <span class="math inline">\(n\)</span>
leave-one-out risk estimates. While the leave-one-out cross-validation scheme
results in a less biased (albeit, more variable) estimate of risk than the
holdout method, it can be computationally very expensive to implement when <span class="math inline">\(n\)</span>
is large.</p>
<p>We illustrate the usage of the leave-one-out cross-validation scheme with
<code>origami</code> below, using the <code>folds_loo(n)</code> function. In order to set up
<code>folds_loo(n)</code>, similarly to the case of the re-substitution method, we need
only the total number of sampled units over which the cross-validation procedure
is to operate. We show the first two folds generated by leave-one-out
cross-validation below.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="origami.html#cb7-1"></a>folds &lt;-<span class="st"> </span><span class="kw">folds_loo</span>(<span class="kw">nrow</span>(washb_data))</span>
<span id="cb7-2"><a href="origami.html#cb7-2"></a>folds[[<span class="dv">1</span>]]</span>
<span id="cb7-3"><a href="origami.html#cb7-3"></a><span class="op">$</span>v</span>
<span id="cb7-4"><a href="origami.html#cb7-4"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb7-5"><a href="origami.html#cb7-5"></a></span>
<span id="cb7-6"><a href="origami.html#cb7-6"></a><span class="op">$</span>training_set</span>
<span id="cb7-7"><a href="origami.html#cb7-7"></a> [<span class="dv">1</span>]  <span class="dv">2</span>  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">5</span>  <span class="dv">6</span>  <span class="dv">7</span>  <span class="dv">8</span>  <span class="dv">9</span> <span class="dv">10</span> <span class="dv">11</span> <span class="dv">12</span> <span class="dv">13</span> <span class="dv">14</span> <span class="dv">15</span> <span class="dv">16</span> <span class="dv">17</span> <span class="dv">18</span> <span class="dv">19</span> <span class="dv">20</span> <span class="dv">21</span> <span class="dv">22</span> <span class="dv">23</span> <span class="dv">24</span> <span class="dv">25</span> <span class="dv">26</span></span>
<span id="cb7-8"><a href="origami.html#cb7-8"></a>[<span class="dv">26</span>] <span class="dv">27</span> <span class="dv">28</span> <span class="dv">29</span> <span class="dv">30</span></span>
<span id="cb7-9"><a href="origami.html#cb7-9"></a></span>
<span id="cb7-10"><a href="origami.html#cb7-10"></a><span class="op">$</span>validation_set</span>
<span id="cb7-11"><a href="origami.html#cb7-11"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb7-12"><a href="origami.html#cb7-12"></a></span>
<span id="cb7-13"><a href="origami.html#cb7-13"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb7-14"><a href="origami.html#cb7-14"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span>
<span id="cb7-15"><a href="origami.html#cb7-15"></a>folds[[<span class="dv">2</span>]]</span>
<span id="cb7-16"><a href="origami.html#cb7-16"></a><span class="op">$</span>v</span>
<span id="cb7-17"><a href="origami.html#cb7-17"></a>[<span class="dv">1</span>] <span class="dv">2</span></span>
<span id="cb7-18"><a href="origami.html#cb7-18"></a></span>
<span id="cb7-19"><a href="origami.html#cb7-19"></a><span class="op">$</span>training_set</span>
<span id="cb7-20"><a href="origami.html#cb7-20"></a> [<span class="dv">1</span>]  <span class="dv">1</span>  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">5</span>  <span class="dv">6</span>  <span class="dv">7</span>  <span class="dv">8</span>  <span class="dv">9</span> <span class="dv">10</span> <span class="dv">11</span> <span class="dv">12</span> <span class="dv">13</span> <span class="dv">14</span> <span class="dv">15</span> <span class="dv">16</span> <span class="dv">17</span> <span class="dv">18</span> <span class="dv">19</span> <span class="dv">20</span> <span class="dv">21</span> <span class="dv">22</span> <span class="dv">23</span> <span class="dv">24</span> <span class="dv">25</span> <span class="dv">26</span></span>
<span id="cb7-21"><a href="origami.html#cb7-21"></a>[<span class="dv">26</span>] <span class="dv">27</span> <span class="dv">28</span> <span class="dv">29</span> <span class="dv">30</span></span>
<span id="cb7-22"><a href="origami.html#cb7-22"></a></span>
<span id="cb7-23"><a href="origami.html#cb7-23"></a><span class="op">$</span>validation_set</span>
<span id="cb7-24"><a href="origami.html#cb7-24"></a>[<span class="dv">1</span>] <span class="dv">2</span></span>
<span id="cb7-25"><a href="origami.html#cb7-25"></a></span>
<span id="cb7-26"><a href="origami.html#cb7-26"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb7-27"><a href="origami.html#cb7-27"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span></code></pre></div>
<!--
nh: should we comment briefly on the displayed structure of the training
and validation folds?
-->
</div>
<div id="v-fold" class="section level4">
<h4>
<span class="header-section-number">2.5.1.4</span> <span class="math inline">\(V\)</span>-fold<a class="anchor" aria-label="anchor" href="#v-fold"><i class="fas fa-link"></i></a>
</h4>
<p>An alternative to the leave-one-out scheme is <span class="math inline">\(V\)</span>-fold cross-validation. This
cross-validation scheme randomly divides the dataset into <span class="math inline">\(V\)</span> splits of
equal (or approximately equal) size. For each split <span class="math inline">\(v=1,\ldots,V\)</span>, the
<span class="math inline">\(v\)</span>th fold is defined by the <span class="math inline">\(v\)</span>th split (which defines the validation set for
fold <span class="math inline">\(v\)</span>) and the complement of the <span class="math inline">\(v\)</span>th split (which defines the training set
for fold <span class="math inline">\(v\)</span>). The algorithms are fit <span class="math inline">\(V\)</span> times separately, to each of the
<span class="math inline">\(V\)</span> training sets. The risk of each fold’s fitted algorithms is then evaluated
via predictions obtained from the validation set. The cross-validated risk for
a fitted algorithm, for example the MSE, is its average risk across all folds.
With <span class="math inline">\(V\)</span>-fold cross-validation, all of the observations
are used in the training and validation stages, preventing the candidate
learning algorithm from overfitting to only a subset of the data (e.g., a given
training set).</p>
<p>For a dataset with <span class="math inline">\(n\)</span> sampled units, <span class="math inline">\(V\)</span>-fold cross-validation with <span class="math inline">\(v=n\)</span>
merely reduces to leave-one-out. Similarly, if we set <span class="math inline">\(n=1\)</span>, we can get the
holdout method’s estimate of the candidate learning algorithm’s performance.
Beyond its computational advantages, <span class="math inline">\(V\)</span>-fold cross-validation often yields more
accurate estimates of the true, underlying risk. This is rooted in the differing
bias-variance trade-offs associated with these two cross-validation schemes:
While the leave-one-out scheme may be less biased, it has much greater variance
(since only a single unit is included in the validation set). This difference
becomes more obvious as <span class="math inline">\(n\)</span> becomes much greater than <span class="math inline">\(v\)</span>. With the <span class="math inline">\(V\)</span>-fold
cross-validation scheme, we end up averaging risk estimates across the <span class="math inline">\(v\)</span>
validation folds, which are typically less correlated than the risk estimates
from the leave-one-out fits. Owing to the fact that the mean of many highly
correlated quantities has higher variance, leave-one-out estimates of the risk
will have higher variance than the corresponding estimates based on <span class="math inline">\(V\)</span>-fold
cross-validation.</p>
<p>Now, let’s see <span class="math inline">\(V\)</span>-fold cross-validation with <code>origami</code> in action! In the next
chapter, we will turn to studying the Super Learner algorithm — an algorithm
capable of selecting the “best” algorithm from among a large library of candidate
learning algorithms – which we’d like to fit <em>and</em> evaluate the performance of.
The Super Learner algorithm relies on <span class="math inline">\(V\)</span>-fold cross-validation as its default
cross-validation scheme. In order to set up <span class="math inline">\(V\)</span>-fold cross-validation, we need
to call <code>origami</code>’s <code>folds_vfold(n, V)</code> function. The two required arguments for
<code>folds_vfold(n, V)</code> are the total number of sample units to be cross-validated
and the number of folds we wish to have.</p>
<p>For example, at <span class="math inline">\(V=2\)</span>, we will get two folds, each with approximately <span class="math inline">\(n/2\)</span>
sampled units in the training and validation sets.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="origami.html#cb8-1"></a>folds &lt;-<span class="st"> </span><span class="kw">folds_vfold</span>(<span class="kw">nrow</span>(washb_data), <span class="dt">V =</span> <span class="dv">2</span>)</span>
<span id="cb8-2"><a href="origami.html#cb8-2"></a>folds[[<span class="dv">1</span>]]</span>
<span id="cb8-3"><a href="origami.html#cb8-3"></a><span class="op">$</span>v</span>
<span id="cb8-4"><a href="origami.html#cb8-4"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb8-5"><a href="origami.html#cb8-5"></a></span>
<span id="cb8-6"><a href="origami.html#cb8-6"></a><span class="op">$</span>training_set</span>
<span id="cb8-7"><a href="origami.html#cb8-7"></a> [<span class="dv">1</span>]  <span class="dv">2</span>  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">6</span>  <span class="dv">7</span>  <span class="dv">8</span> <span class="dv">11</span> <span class="dv">12</span> <span class="dv">14</span> <span class="dv">15</span> <span class="dv">19</span> <span class="dv">22</span> <span class="dv">23</span> <span class="dv">24</span> <span class="dv">28</span></span>
<span id="cb8-8"><a href="origami.html#cb8-8"></a></span>
<span id="cb8-9"><a href="origami.html#cb8-9"></a><span class="op">$</span>validation_set</span>
<span id="cb8-10"><a href="origami.html#cb8-10"></a> [<span class="dv">1</span>]  <span class="dv">1</span>  <span class="dv">5</span>  <span class="dv">9</span> <span class="dv">10</span> <span class="dv">13</span> <span class="dv">16</span> <span class="dv">17</span> <span class="dv">18</span> <span class="dv">20</span> <span class="dv">21</span> <span class="dv">25</span> <span class="dv">26</span> <span class="dv">27</span> <span class="dv">29</span> <span class="dv">30</span></span>
<span id="cb8-11"><a href="origami.html#cb8-11"></a></span>
<span id="cb8-12"><a href="origami.html#cb8-12"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb8-13"><a href="origami.html#cb8-13"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span>
<span id="cb8-14"><a href="origami.html#cb8-14"></a>folds[[<span class="dv">2</span>]]</span>
<span id="cb8-15"><a href="origami.html#cb8-15"></a><span class="op">$</span>v</span>
<span id="cb8-16"><a href="origami.html#cb8-16"></a>[<span class="dv">1</span>] <span class="dv">2</span></span>
<span id="cb8-17"><a href="origami.html#cb8-17"></a></span>
<span id="cb8-18"><a href="origami.html#cb8-18"></a><span class="op">$</span>training_set</span>
<span id="cb8-19"><a href="origami.html#cb8-19"></a> [<span class="dv">1</span>]  <span class="dv">1</span>  <span class="dv">5</span>  <span class="dv">9</span> <span class="dv">10</span> <span class="dv">13</span> <span class="dv">16</span> <span class="dv">17</span> <span class="dv">18</span> <span class="dv">20</span> <span class="dv">21</span> <span class="dv">25</span> <span class="dv">26</span> <span class="dv">27</span> <span class="dv">29</span> <span class="dv">30</span></span>
<span id="cb8-20"><a href="origami.html#cb8-20"></a></span>
<span id="cb8-21"><a href="origami.html#cb8-21"></a><span class="op">$</span>validation_set</span>
<span id="cb8-22"><a href="origami.html#cb8-22"></a> [<span class="dv">1</span>]  <span class="dv">2</span>  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">6</span>  <span class="dv">7</span>  <span class="dv">8</span> <span class="dv">11</span> <span class="dv">12</span> <span class="dv">14</span> <span class="dv">15</span> <span class="dv">19</span> <span class="dv">22</span> <span class="dv">23</span> <span class="dv">24</span> <span class="dv">28</span></span>
<span id="cb8-23"><a href="origami.html#cb8-23"></a></span>
<span id="cb8-24"><a href="origami.html#cb8-24"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb8-25"><a href="origami.html#cb8-25"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span></code></pre></div>
<!--
nh: should we comment briefly on the displayed structure of the training
and validation folds?
-->
</div>
<div id="monte-carlo" class="section level4">
<h4>
<span class="header-section-number">2.5.1.5</span> Monte Carlo<a class="anchor" aria-label="anchor" href="#monte-carlo"><i class="fas fa-link"></i></a>
</h4>
<p>In the Monte Carlo cross-validation scheme, we randomly select some fraction of
the data, <em>without replacement</em>, to form the training set, assigning the
remainder of the sampled units to the validation set. In this way, the dataset
is randomly divided into two independent splits: A training set of <span class="math inline">\(n_0 = n \cdot (1 - p)\)</span> observations and a validation set of <span class="math inline">\(n_1 = n \cdot p\)</span>
observations. By repeating this procedure many times, the Monte Carlo
cross-validation scheme generates, at random, many training and validation
partitions of the dataset.</p>
<p>Since the partitions are independent across folds, the same observational unit
can appear in the validation set multiple times; note that this is a stark
difference between the Monte Carlo and <span class="math inline">\(V\)</span>-fold cross-validation schemes. For a
given sampling fraction <span class="math inline">\(p\)</span>, the Monte Carlo cross-validation scheme would be
optimal if repeated infinitely many times — of course, this is not
computationally feasible. With Monte Carlo cross-validation, it is possible to
explore many more partitions of the dataset than with <span class="math inline">\(V\)</span>-fold cross-validation,
resulting in (possibly) less variable estimates of the risk (across partitions),
though this comes at the cost of an increase in bias (because the splits are
correlated). Because Monte Carlo cross-validation generates many splits with
overlaps in the sampled units, more splits (and thus more computational time)
will be necessary to achieve the level of performance (in terms of unbiasedness)
that the <span class="math inline">\(V\)</span>-fold cross-validation scheme achieves with only <span class="math inline">\(V\)</span> splits.</p>
<p>We illustrate the usage of the Monte Carlo cross-validation scheme with
<code>origami</code> below, using the <code>folds_montecarlo(n, V, pvalidation)</code> function. In
order to set up <code>folds_montecarlo(n, V, pvalidation)</code>, we need the following,</p>
<ol style="list-style-type: decimal">
<li>the total number of observations we wish to cross-validate;</li>
<li>the number of folds; and</li>
<li>the proportion of observations to be placed in the validation set.</li>
</ol>
<p>For example, setting <span class="math inline">\(V=2\)</span> and <span class="math inline">\(pvalidation = 0.2\)</span>, we obtain two folds, each
with approximately <span class="math inline">\(6\)</span> sampled units in the validation set for each fold.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="origami.html#cb9-1"></a>folds &lt;-<span class="st"> </span><span class="kw">folds_montecarlo</span>(<span class="kw">nrow</span>(washb_data), <span class="dt">V =</span> <span class="dv">2</span>, <span class="dt">pvalidation =</span> <span class="fl">0.2</span>)</span>
<span id="cb9-2"><a href="origami.html#cb9-2"></a>folds[[<span class="dv">1</span>]]</span>
<span id="cb9-3"><a href="origami.html#cb9-3"></a><span class="op">$</span>v</span>
<span id="cb9-4"><a href="origami.html#cb9-4"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb9-5"><a href="origami.html#cb9-5"></a></span>
<span id="cb9-6"><a href="origami.html#cb9-6"></a><span class="op">$</span>training_set</span>
<span id="cb9-7"><a href="origami.html#cb9-7"></a> [<span class="dv">1</span>] <span class="dv">19</span> <span class="dv">27</span> <span class="dv">16</span> <span class="dv">29</span> <span class="dv">23</span> <span class="dv">12</span>  <span class="dv">1</span>  <span class="dv">3</span> <span class="dv">18</span> <span class="dv">11</span>  <span class="dv">5</span>  <span class="dv">7</span>  <span class="dv">8</span>  <span class="dv">6</span>  <span class="dv">9</span> <span class="dv">22</span> <span class="dv">10</span> <span class="dv">25</span> <span class="dv">20</span> <span class="dv">28</span> <span class="dv">15</span>  <span class="dv">2</span> <span class="dv">24</span> <span class="dv">26</span></span>
<span id="cb9-8"><a href="origami.html#cb9-8"></a></span>
<span id="cb9-9"><a href="origami.html#cb9-9"></a><span class="op">$</span>validation_set</span>
<span id="cb9-10"><a href="origami.html#cb9-10"></a>[<span class="dv">1</span>]  <span class="dv">4</span> <span class="dv">13</span> <span class="dv">14</span> <span class="dv">17</span> <span class="dv">21</span> <span class="dv">30</span></span>
<span id="cb9-11"><a href="origami.html#cb9-11"></a></span>
<span id="cb9-12"><a href="origami.html#cb9-12"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb9-13"><a href="origami.html#cb9-13"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span>
<span id="cb9-14"><a href="origami.html#cb9-14"></a>folds[[<span class="dv">2</span>]]</span>
<span id="cb9-15"><a href="origami.html#cb9-15"></a><span class="op">$</span>v</span>
<span id="cb9-16"><a href="origami.html#cb9-16"></a>[<span class="dv">1</span>] <span class="dv">2</span></span>
<span id="cb9-17"><a href="origami.html#cb9-17"></a></span>
<span id="cb9-18"><a href="origami.html#cb9-18"></a><span class="op">$</span>training_set</span>
<span id="cb9-19"><a href="origami.html#cb9-19"></a> [<span class="dv">1</span>] <span class="dv">19</span> <span class="dv">15</span> <span class="dv">28</span> <span class="dv">25</span> <span class="dv">29</span> <span class="dv">11</span> <span class="dv">20</span> <span class="dv">17</span> <span class="dv">14</span>  <span class="dv">4</span>  <span class="dv">9</span> <span class="dv">12</span> <span class="dv">30</span>  <span class="dv">8</span> <span class="dv">27</span> <span class="dv">18</span> <span class="dv">16</span> <span class="dv">10</span> <span class="dv">13</span>  <span class="dv">6</span> <span class="dv">24</span>  <span class="dv">3</span> <span class="dv">26</span>  <span class="dv">1</span></span>
<span id="cb9-20"><a href="origami.html#cb9-20"></a></span>
<span id="cb9-21"><a href="origami.html#cb9-21"></a><span class="op">$</span>validation_set</span>
<span id="cb9-22"><a href="origami.html#cb9-22"></a>[<span class="dv">1</span>]  <span class="dv">2</span>  <span class="dv">5</span>  <span class="dv">7</span> <span class="dv">21</span> <span class="dv">22</span> <span class="dv">23</span></span>
<span id="cb9-23"><a href="origami.html#cb9-23"></a></span>
<span id="cb9-24"><a href="origami.html#cb9-24"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb9-25"><a href="origami.html#cb9-25"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span></code></pre></div>
<!--
nh: should we comment briefly on the displayed structure of the training
and validation folds?
-->
</div>
<div id="bootstrap" class="section level4">
<h4>
<span class="header-section-number">2.5.1.6</span> Bootstrap<a class="anchor" aria-label="anchor" href="#bootstrap"><i class="fas fa-link"></i></a>
</h4>
<p>Like the Monte Carlo cross-validation scheme, the bootstrap cross-validation
scheme also consists of randomly selecting sampled units, <em>with replacement</em>,
for the training set; the rest of the sampled units are allocated to the
validation set. This process is then repeated multiple times, generating (at
random) new training and validation partitions of the dataset each time. In
contrast to the Monte Carlo cross-validation scheme, the total number of sampled
units in training and validation sets (i.e., the sizes of the two partitions)
across folds is not held constant. Also, as the name suggests, sampling is
performed with replacement (as in the bootstrap <span class="citation">(Davison and Hinkley <a href="references.html#ref-davison1997bootstrap" role="doc-biblioref">1997</a>)</span>), hence
the exact same observational units may be included in multiple training sets.
The proportion of observational units in the validation sets is a random
variable, with expectation <span class="math inline">\(\sim 0.368\)</span>.
<!--
nh: I don't follow the last bit about the proportion -- might be that I'm
missing something but it seems to be coming out of nowhere
--></p>
<p>We illustrate the usage of the bootstrap cross-validation scheme with <code>origami</code>
below, using the <code>folds_bootstrap(n, V)</code> function. In order to set up
<code>folds_bootstrap(n, V)</code>, we need to specify the following arguments:</p>
<ol style="list-style-type: decimal">
<li>the total number of observations we wish to cross-validate; and</li>
<li>the number of folds.</li>
</ol>
<p>For example, setting <span class="math inline">\(V=2\)</span>, we obtain two folds, each with different numbers of
sampled units in the validation sets across the folds.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="origami.html#cb10-1"></a>folds &lt;-<span class="st"> </span><span class="kw">folds_bootstrap</span>(<span class="kw">nrow</span>(washb_data), <span class="dt">V =</span> <span class="dv">2</span>)</span>
<span id="cb10-2"><a href="origami.html#cb10-2"></a>folds[[<span class="dv">1</span>]]</span>
<span id="cb10-3"><a href="origami.html#cb10-3"></a><span class="op">$</span>v</span>
<span id="cb10-4"><a href="origami.html#cb10-4"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb10-5"><a href="origami.html#cb10-5"></a></span>
<span id="cb10-6"><a href="origami.html#cb10-6"></a><span class="op">$</span>training_set</span>
<span id="cb10-7"><a href="origami.html#cb10-7"></a> [<span class="dv">1</span>]  <span class="dv">2</span>  <span class="dv">5</span> <span class="dv">30</span>  <span class="dv">1</span> <span class="dv">29</span> <span class="dv">16</span> <span class="dv">10</span> <span class="dv">11</span>  <span class="dv">8</span> <span class="dv">25</span> <span class="dv">28</span>  <span class="dv">2</span> <span class="dv">11</span>  <span class="dv">2</span> <span class="dv">16</span> <span class="dv">28</span> <span class="dv">15</span> <span class="dv">28</span>  <span class="dv">1</span> <span class="dv">27</span>  <span class="dv">9</span> <span class="dv">19</span> <span class="dv">20</span> <span class="dv">30</span> <span class="dv">18</span></span>
<span id="cb10-8"><a href="origami.html#cb10-8"></a>[<span class="dv">26</span>] <span class="dv">11</span> <span class="dv">13</span>  <span class="dv">2</span> <span class="dv">18</span> <span class="dv">12</span></span>
<span id="cb10-9"><a href="origami.html#cb10-9"></a></span>
<span id="cb10-10"><a href="origami.html#cb10-10"></a><span class="op">$</span>validation_set</span>
<span id="cb10-11"><a href="origami.html#cb10-11"></a> [<span class="dv">1</span>]  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">6</span>  <span class="dv">7</span> <span class="dv">14</span> <span class="dv">17</span> <span class="dv">21</span> <span class="dv">22</span> <span class="dv">23</span> <span class="dv">24</span> <span class="dv">26</span></span>
<span id="cb10-12"><a href="origami.html#cb10-12"></a></span>
<span id="cb10-13"><a href="origami.html#cb10-13"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb10-14"><a href="origami.html#cb10-14"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span>
<span id="cb10-15"><a href="origami.html#cb10-15"></a>folds[[<span class="dv">2</span>]]</span>
<span id="cb10-16"><a href="origami.html#cb10-16"></a><span class="op">$</span>v</span>
<span id="cb10-17"><a href="origami.html#cb10-17"></a>[<span class="dv">1</span>] <span class="dv">2</span></span>
<span id="cb10-18"><a href="origami.html#cb10-18"></a></span>
<span id="cb10-19"><a href="origami.html#cb10-19"></a><span class="op">$</span>training_set</span>
<span id="cb10-20"><a href="origami.html#cb10-20"></a> [<span class="dv">1</span>] <span class="dv">12</span> <span class="dv">16</span> <span class="dv">10</span> <span class="dv">29</span> <span class="dv">22</span> <span class="dv">15</span> <span class="dv">27</span>  <span class="dv">9</span> <span class="dv">27</span> <span class="dv">16</span> <span class="dv">12</span> <span class="dv">28</span> <span class="dv">10</span> <span class="dv">28</span> <span class="dv">26</span>  <span class="dv">1</span> <span class="dv">14</span>  <span class="dv">6</span> <span class="dv">23</span> <span class="dv">14</span> <span class="dv">21</span> <span class="dv">16</span>  <span class="dv">5</span> <span class="dv">20</span>  <span class="dv">8</span></span>
<span id="cb10-21"><a href="origami.html#cb10-21"></a>[<span class="dv">26</span>] <span class="dv">23</span> <span class="dv">25</span>  <span class="dv">8</span> <span class="dv">27</span>  <span class="dv">5</span></span>
<span id="cb10-22"><a href="origami.html#cb10-22"></a></span>
<span id="cb10-23"><a href="origami.html#cb10-23"></a><span class="op">$</span>validation_set</span>
<span id="cb10-24"><a href="origami.html#cb10-24"></a> [<span class="dv">1</span>]  <span class="dv">2</span>  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">7</span> <span class="dv">11</span> <span class="dv">13</span> <span class="dv">17</span> <span class="dv">18</span> <span class="dv">19</span> <span class="dv">24</span> <span class="dv">30</span></span>
<span id="cb10-25"><a href="origami.html#cb10-25"></a></span>
<span id="cb10-26"><a href="origami.html#cb10-26"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb10-27"><a href="origami.html#cb10-27"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span></code></pre></div>
<!--
nh: should we comment briefly on the displayed structure of the training
and validation folds?
-->
<!--
RP: 
Should we add stratified cross-validation and clustered cross-validation examples
with origami?
I think these are both pretty common
-->
</div>
</div>
<div id="cross-validation-for-time-series-data" class="section level3">
<h3>
<span class="header-section-number">2.5.2</span> Cross-validation for Time-series Data<a class="anchor" aria-label="anchor" href="#cross-validation-for-time-series-data"><i class="fas fa-link"></i></a>
</h3>
<p>The <code>origami</code> package also supports numerous cross-validation schemes for
time-series data, for both single and multiple time-series
with arbitrary time and network dependence.</p>
</div>
<div id="airpassenger-data-example" class="section level3 unnumbered">
<h3>
<code>AirPassenger</code> Data Example<a class="anchor" aria-label="anchor" href="#airpassenger-data-example"><i class="fas fa-link"></i></a>
</h3>
<p>In order to illustrate different cross-validation schemes for time-series, we
will be using the <em>AirPassenger</em> data; this is a widely used, freely available
dataset. The <em>AirPassenger</em> dataset, included in <code>R</code>, provides monthly totals of
international airline passengers between the years 1949 and 1960.</p>
<p><strong>Goal:</strong> we want to forecast the number of airline passengers at time <span class="math inline">\(h\)</span>
horizon using the historical data from 1949 to 1960.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/sinhrks/ggfortify">ggfortify</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">AirPassengers</span><span class="op">)</span></span>
<span><span class="va">AP</span> <span class="op">&lt;-</span> <span class="va">AirPassengers</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">AP</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    x <span class="op">=</span> <span class="st">"Date"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Passenger numbers (1000's)"</span>,</span>
<span>    title <span class="op">=</span> <span class="st">"Air Passengers from 1949 to 1961"</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="va">t</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">AP</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="06-origami_files/figure-html/plot_airpass-1.png" width="80%" style="display: block; margin: auto;"></div>
<div id="rolling-origin" class="section level4">
<h4>
<span class="header-section-number">2.5.2.1</span> Rolling origin<a class="anchor" aria-label="anchor" href="#rolling-origin"><i class="fas fa-link"></i></a>
</h4>
<p>The rolling origin cross-validation scheme lends itself to “online” learning
algorithms, in which large streams of data have to be fit continually
(respecting time), where the fit of the learning algorithm is (constantly)
updated as more data accrues. In general, the rolling origin scheme defines an
initial training set, and, with each iteration, the size of the training set
grows by a batch of <span class="math inline">\(m\)</span> observations, the size of the validation set remains
constant, there might be a gap between training and validation times of size
<span class="math inline">\(h\)</span> (a lag window), and new folds are added until time <span class="math inline">\(t\)</span> is reached in the
validation set. The time points included in the training set always lag behind
behind those in the validation set.</p>
<p>To further illustrate rolling origin cross-validation, we show below an example
that yields three folds. Here, the first window size is fifteen time points, on
which we first train the candidate learning algorithm. We then evaluate its
performance on ten time points with a gap (<span class="math inline">\(h\)</span>) of five time points between the
training and validation sets.</p>
<p>In the following, we train the learning algorithm on a longer stream of data, 25
time points, including the original fifteen with which we initially started.
Then, we evaluate its performance at a (temporal) distance ten time points
ahead.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-1"></span>
<img src="img/png/rolling_origin.png" alt="Rolling origin CV" width="80%"><p class="caption">
FIGURE 2.1: Rolling origin CV
</p>
</div>
<p>We illustrate the usage of the rolling origin cross-validation scheme with
<code>origami</code> below, using the <code>folds_rolling_origin(n, first_window, validation_size, gap, batch)</code> function. In order to set up
<code>folds_rolling_origin(n, first_window, validation_size, gap, batch)</code>, we need
the following,</p>
<ol style="list-style-type: decimal">
<li>the total number of time points we wish to cross-validate (<code>n</code>);</li>
<li>the size of the first training set (<code>first_window</code>);</li>
<li>the size of the validation set (<code>validation_size</code>);</li>
<li>the gap between training and validation set(<code>gap</code>); and</li>
<li>the size of the training set update per iteration of cross-validation (<code>batch</code>).</li>
</ol>
<p>Our time-series has <span class="math inline">\(t=144\)</span> time points. Setting <code>first_window</code> to <span class="math inline">\(50\)</span>,
<code>validation_size</code> to 10, <code>gap</code> to 5, and <code>batch</code> to 20 yields four time-series
folds; we show the first two below.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="origami.html#cb12-1"></a>folds &lt;-<span class="st"> </span><span class="kw">folds_rolling_origin</span>(</span>
<span id="cb12-2"><a href="origami.html#cb12-2"></a>  <span class="dt">n =</span> t,</span>
<span id="cb12-3"><a href="origami.html#cb12-3"></a>  <span class="dt">first_window =</span> <span class="dv">50</span>, <span class="dt">validation_size =</span> <span class="dv">10</span>, <span class="dt">gap =</span> <span class="dv">5</span>, <span class="dt">batch =</span> <span class="dv">20</span></span>
<span id="cb12-4"><a href="origami.html#cb12-4"></a>)</span>
<span id="cb12-5"><a href="origami.html#cb12-5"></a>folds[[<span class="dv">1</span>]]</span>
<span id="cb12-6"><a href="origami.html#cb12-6"></a><span class="op">$</span>v</span>
<span id="cb12-7"><a href="origami.html#cb12-7"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb12-8"><a href="origami.html#cb12-8"></a></span>
<span id="cb12-9"><a href="origami.html#cb12-9"></a><span class="op">$</span>training_set</span>
<span id="cb12-10"><a href="origami.html#cb12-10"></a> [<span class="dv">1</span>]  <span class="dv">1</span>  <span class="dv">2</span>  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">5</span>  <span class="dv">6</span>  <span class="dv">7</span>  <span class="dv">8</span>  <span class="dv">9</span> <span class="dv">10</span> <span class="dv">11</span> <span class="dv">12</span> <span class="dv">13</span> <span class="dv">14</span> <span class="dv">15</span> <span class="dv">16</span> <span class="dv">17</span> <span class="dv">18</span> <span class="dv">19</span> <span class="dv">20</span> <span class="dv">21</span> <span class="dv">22</span> <span class="dv">23</span> <span class="dv">24</span> <span class="dv">25</span></span>
<span id="cb12-11"><a href="origami.html#cb12-11"></a>[<span class="dv">26</span>] <span class="dv">26</span> <span class="dv">27</span> <span class="dv">28</span> <span class="dv">29</span> <span class="dv">30</span> <span class="dv">31</span> <span class="dv">32</span> <span class="dv">33</span> <span class="dv">34</span> <span class="dv">35</span> <span class="dv">36</span> <span class="dv">37</span> <span class="dv">38</span> <span class="dv">39</span> <span class="dv">40</span> <span class="dv">41</span> <span class="dv">42</span> <span class="dv">43</span> <span class="dv">44</span> <span class="dv">45</span> <span class="dv">46</span> <span class="dv">47</span> <span class="dv">48</span> <span class="dv">49</span> <span class="dv">50</span></span>
<span id="cb12-12"><a href="origami.html#cb12-12"></a></span>
<span id="cb12-13"><a href="origami.html#cb12-13"></a><span class="op">$</span>validation_set</span>
<span id="cb12-14"><a href="origami.html#cb12-14"></a> [<span class="dv">1</span>] <span class="dv">56</span> <span class="dv">57</span> <span class="dv">58</span> <span class="dv">59</span> <span class="dv">60</span> <span class="dv">61</span> <span class="dv">62</span> <span class="dv">63</span> <span class="dv">64</span> <span class="dv">65</span></span>
<span id="cb12-15"><a href="origami.html#cb12-15"></a></span>
<span id="cb12-16"><a href="origami.html#cb12-16"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb12-17"><a href="origami.html#cb12-17"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span>
<span id="cb12-18"><a href="origami.html#cb12-18"></a>folds[[<span class="dv">2</span>]]</span>
<span id="cb12-19"><a href="origami.html#cb12-19"></a><span class="op">$</span>v</span>
<span id="cb12-20"><a href="origami.html#cb12-20"></a>[<span class="dv">1</span>] <span class="dv">2</span></span>
<span id="cb12-21"><a href="origami.html#cb12-21"></a></span>
<span id="cb12-22"><a href="origami.html#cb12-22"></a><span class="op">$</span>training_set</span>
<span id="cb12-23"><a href="origami.html#cb12-23"></a> [<span class="dv">1</span>]  <span class="dv">1</span>  <span class="dv">2</span>  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">5</span>  <span class="dv">6</span>  <span class="dv">7</span>  <span class="dv">8</span>  <span class="dv">9</span> <span class="dv">10</span> <span class="dv">11</span> <span class="dv">12</span> <span class="dv">13</span> <span class="dv">14</span> <span class="dv">15</span> <span class="dv">16</span> <span class="dv">17</span> <span class="dv">18</span> <span class="dv">19</span> <span class="dv">20</span> <span class="dv">21</span> <span class="dv">22</span> <span class="dv">23</span> <span class="dv">24</span> <span class="dv">25</span></span>
<span id="cb12-24"><a href="origami.html#cb12-24"></a>[<span class="dv">26</span>] <span class="dv">26</span> <span class="dv">27</span> <span class="dv">28</span> <span class="dv">29</span> <span class="dv">30</span> <span class="dv">31</span> <span class="dv">32</span> <span class="dv">33</span> <span class="dv">34</span> <span class="dv">35</span> <span class="dv">36</span> <span class="dv">37</span> <span class="dv">38</span> <span class="dv">39</span> <span class="dv">40</span> <span class="dv">41</span> <span class="dv">42</span> <span class="dv">43</span> <span class="dv">44</span> <span class="dv">45</span> <span class="dv">46</span> <span class="dv">47</span> <span class="dv">48</span> <span class="dv">49</span> <span class="dv">50</span></span>
<span id="cb12-25"><a href="origami.html#cb12-25"></a>[<span class="dv">51</span>] <span class="dv">51</span> <span class="dv">52</span> <span class="dv">53</span> <span class="dv">54</span> <span class="dv">55</span> <span class="dv">56</span> <span class="dv">57</span> <span class="dv">58</span> <span class="dv">59</span> <span class="dv">60</span> <span class="dv">61</span> <span class="dv">62</span> <span class="dv">63</span> <span class="dv">64</span> <span class="dv">65</span> <span class="dv">66</span> <span class="dv">67</span> <span class="dv">68</span> <span class="dv">69</span> <span class="dv">70</span></span>
<span id="cb12-26"><a href="origami.html#cb12-26"></a></span>
<span id="cb12-27"><a href="origami.html#cb12-27"></a><span class="op">$</span>validation_set</span>
<span id="cb12-28"><a href="origami.html#cb12-28"></a> [<span class="dv">1</span>] <span class="dv">76</span> <span class="dv">77</span> <span class="dv">78</span> <span class="dv">79</span> <span class="dv">80</span> <span class="dv">81</span> <span class="dv">82</span> <span class="dv">83</span> <span class="dv">84</span> <span class="dv">85</span></span>
<span id="cb12-29"><a href="origami.html#cb12-29"></a></span>
<span id="cb12-30"><a href="origami.html#cb12-30"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb12-31"><a href="origami.html#cb12-31"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span></code></pre></div>
<!--
nh: should we comment briefly on the displayed structure of the training
and validation folds?
-->
</div>
<div id="rolling-window" class="section level4">
<h4>
<span class="header-section-number">2.5.2.2</span> Rolling window<a class="anchor" aria-label="anchor" href="#rolling-window"><i class="fas fa-link"></i></a>
</h4>
<p>Rather than adding more and more time points to the training set in each
iteration of cross-validation (as under the rolling origin scheme), the rolling
window cross-validation scheme “rolls” the training sample forward in time by
<span class="math inline">\(m\)</span> units (of time). This strategy can be useful, for example, in settings with
parametric learning algorithms, which are often very sensitive to moment (e.g.,
mean, variance) or parameter drift, which is itself challenging to explicitly
account for in the model construction step. The rolling window scheme is also
computationally more efficient, and possibly warranted over rolling origin
when working in streaming data analysis where the training data is too large
for convenient access. In contrast to the
rolling origin scheme, the sampled units in the training set are always the same
for each iteration of the rolling window scheme.</p>
<p>The illustration below depicts rolling window cross-validation using three
time-series folds. The first window size is 15 time points, on which we first
train the candidate learning algorithm. As in the previous illustration, we
evaluate its performance on 10 time points, with a gap of size 5 time points
between the training and validation sets. However, for the next fold, we train
the learning algorithm on time points further away from the origin (here, 10
time points). Note that the size of the training set in the new fold is the same
as in the first fold (both include 15 time points). This setup keeps the
training sets comparable over time (and across folds), unlike under the rolling
origin cross-validation scheme. We then evaluate the performance of the
candidate learning algorithm on 10 time points in the future.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-2"></span>
<img src="img/png/rolling_window.png" alt="Rolling window CV" width="80%"><p class="caption">
FIGURE 2.2: Rolling window CV
</p>
</div>
<p>We demonstrate the usage of the rolling window cross-validation scheme with
<code>origami</code> below, using the <code>folds_rolling_window(n, window_size, validation_size, gap, batch)</code> function. In order to set up
<code>folds_rolling_window(n, window_size, validation_size, gap, batch)</code>, we need to
specify the following arguments:</p>
<ol style="list-style-type: decimal">
<li>the total number of time points we wish to cross-validate (<code>n</code>);</li>
<li>the size of the training sets (<code>window_size</code>);</li>
<li>the size of the validation set (<code>validation_size</code>);</li>
<li>the gap between training and validation set (<code>gap</code>); and</li>
<li>the size of the training set update per iteration of cross-validation (<code>batch</code>).</li>
</ol>
<p>Setting the <code>window_size</code> to <span class="math inline">\(50\)</span>, <code>validation_size</code> to 10, <code>gap</code> to 5 and
<code>batch</code> to 20, we also get 4 time-series folds; we show the first two below.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="origami.html#cb13-1"></a>folds &lt;-<span class="st"> </span><span class="kw">folds_rolling_window</span>(</span>
<span id="cb13-2"><a href="origami.html#cb13-2"></a>  <span class="dt">n =</span> t,</span>
<span id="cb13-3"><a href="origami.html#cb13-3"></a>  <span class="dt">window_size =</span> <span class="dv">50</span>, <span class="dt">validation_size =</span> <span class="dv">10</span>, <span class="dt">gap =</span> <span class="dv">5</span>, <span class="dt">batch =</span> <span class="dv">20</span></span>
<span id="cb13-4"><a href="origami.html#cb13-4"></a>)</span>
<span id="cb13-5"><a href="origami.html#cb13-5"></a>folds[[<span class="dv">1</span>]]</span>
<span id="cb13-6"><a href="origami.html#cb13-6"></a><span class="op">$</span>v</span>
<span id="cb13-7"><a href="origami.html#cb13-7"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb13-8"><a href="origami.html#cb13-8"></a></span>
<span id="cb13-9"><a href="origami.html#cb13-9"></a><span class="op">$</span>training_set</span>
<span id="cb13-10"><a href="origami.html#cb13-10"></a> [<span class="dv">1</span>]  <span class="dv">1</span>  <span class="dv">2</span>  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">5</span>  <span class="dv">6</span>  <span class="dv">7</span>  <span class="dv">8</span>  <span class="dv">9</span> <span class="dv">10</span> <span class="dv">11</span> <span class="dv">12</span> <span class="dv">13</span> <span class="dv">14</span> <span class="dv">15</span> <span class="dv">16</span> <span class="dv">17</span> <span class="dv">18</span> <span class="dv">19</span> <span class="dv">20</span> <span class="dv">21</span> <span class="dv">22</span> <span class="dv">23</span> <span class="dv">24</span> <span class="dv">25</span></span>
<span id="cb13-11"><a href="origami.html#cb13-11"></a>[<span class="dv">26</span>] <span class="dv">26</span> <span class="dv">27</span> <span class="dv">28</span> <span class="dv">29</span> <span class="dv">30</span> <span class="dv">31</span> <span class="dv">32</span> <span class="dv">33</span> <span class="dv">34</span> <span class="dv">35</span> <span class="dv">36</span> <span class="dv">37</span> <span class="dv">38</span> <span class="dv">39</span> <span class="dv">40</span> <span class="dv">41</span> <span class="dv">42</span> <span class="dv">43</span> <span class="dv">44</span> <span class="dv">45</span> <span class="dv">46</span> <span class="dv">47</span> <span class="dv">48</span> <span class="dv">49</span> <span class="dv">50</span></span>
<span id="cb13-12"><a href="origami.html#cb13-12"></a></span>
<span id="cb13-13"><a href="origami.html#cb13-13"></a><span class="op">$</span>validation_set</span>
<span id="cb13-14"><a href="origami.html#cb13-14"></a> [<span class="dv">1</span>] <span class="dv">56</span> <span class="dv">57</span> <span class="dv">58</span> <span class="dv">59</span> <span class="dv">60</span> <span class="dv">61</span> <span class="dv">62</span> <span class="dv">63</span> <span class="dv">64</span> <span class="dv">65</span></span>
<span id="cb13-15"><a href="origami.html#cb13-15"></a></span>
<span id="cb13-16"><a href="origami.html#cb13-16"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb13-17"><a href="origami.html#cb13-17"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span>
<span id="cb13-18"><a href="origami.html#cb13-18"></a>folds[[<span class="dv">2</span>]]</span>
<span id="cb13-19"><a href="origami.html#cb13-19"></a><span class="op">$</span>v</span>
<span id="cb13-20"><a href="origami.html#cb13-20"></a>[<span class="dv">1</span>] <span class="dv">2</span></span>
<span id="cb13-21"><a href="origami.html#cb13-21"></a></span>
<span id="cb13-22"><a href="origami.html#cb13-22"></a><span class="op">$</span>training_set</span>
<span id="cb13-23"><a href="origami.html#cb13-23"></a> [<span class="dv">1</span>] <span class="dv">21</span> <span class="dv">22</span> <span class="dv">23</span> <span class="dv">24</span> <span class="dv">25</span> <span class="dv">26</span> <span class="dv">27</span> <span class="dv">28</span> <span class="dv">29</span> <span class="dv">30</span> <span class="dv">31</span> <span class="dv">32</span> <span class="dv">33</span> <span class="dv">34</span> <span class="dv">35</span> <span class="dv">36</span> <span class="dv">37</span> <span class="dv">38</span> <span class="dv">39</span> <span class="dv">40</span> <span class="dv">41</span> <span class="dv">42</span> <span class="dv">43</span> <span class="dv">44</span> <span class="dv">45</span></span>
<span id="cb13-24"><a href="origami.html#cb13-24"></a>[<span class="dv">26</span>] <span class="dv">46</span> <span class="dv">47</span> <span class="dv">48</span> <span class="dv">49</span> <span class="dv">50</span> <span class="dv">51</span> <span class="dv">52</span> <span class="dv">53</span> <span class="dv">54</span> <span class="dv">55</span> <span class="dv">56</span> <span class="dv">57</span> <span class="dv">58</span> <span class="dv">59</span> <span class="dv">60</span> <span class="dv">61</span> <span class="dv">62</span> <span class="dv">63</span> <span class="dv">64</span> <span class="dv">65</span> <span class="dv">66</span> <span class="dv">67</span> <span class="dv">68</span> <span class="dv">69</span> <span class="dv">70</span></span>
<span id="cb13-25"><a href="origami.html#cb13-25"></a></span>
<span id="cb13-26"><a href="origami.html#cb13-26"></a><span class="op">$</span>validation_set</span>
<span id="cb13-27"><a href="origami.html#cb13-27"></a> [<span class="dv">1</span>] <span class="dv">76</span> <span class="dv">77</span> <span class="dv">78</span> <span class="dv">79</span> <span class="dv">80</span> <span class="dv">81</span> <span class="dv">82</span> <span class="dv">83</span> <span class="dv">84</span> <span class="dv">85</span></span>
<span id="cb13-28"><a href="origami.html#cb13-28"></a></span>
<span id="cb13-29"><a href="origami.html#cb13-29"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb13-30"><a href="origami.html#cb13-30"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span></code></pre></div>
<!--
nh: should we comment briefly on the displayed structure of the training
and validation folds?
-->
</div>
<div id="rolling-origin-with-v-fold" class="section level4">
<h4>
<span class="header-section-number">2.5.2.3</span> Rolling origin with <span class="math inline">\(V\)</span>-fold<a class="anchor" aria-label="anchor" href="#rolling-origin-with-v-fold"><i class="fas fa-link"></i></a>
</h4>
<p>A variant of the rolling origin cross-validation scheme, accounting for sample
dependence, is the rolling-origin-<span class="math inline">\(V\)</span>-fold cross-validation scheme. In contrast
to the canonical rolling origin scheme, under this hybrid scheme, sampled units
in the training and validation sets are <em>not</em> the same, which this scheme
accomplishes by incorporating <span class="math inline">\(V\)</span>-fold cross-validation within the time-series
setup. Here, the learning algorithm’s predictions are evaluated on the future
time points of the time-series observational units excluded from the training
step, accommodating potential dependence not only across time but also across
observational units. To use the rolling-origin-<span class="math inline">\(V\)</span>-fold cross-validation scheme
with <code>origami</code>, we can invoke the <code>folds_vfold_rolling_origin_pooled(n, t, id, time, V, first_window, validation_size, gap, batch)</code> function. In the figure
below, we show <span class="math inline">\(V=2\)</span> folds, alongside two time-series (rolling origin)
cross-validation folds.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-3"></span>
<img src="img/png/rolling_origin_v_fold.png" alt="Rolling origin V-fold CV" width="80%"><p class="caption">
FIGURE 2.3: Rolling origin V-fold CV
</p>
</div>
</div>
<div id="rolling-window-with-v-fold" class="section level4">
<h4>
<span class="header-section-number">2.5.2.4</span> Rolling window with <span class="math inline">\(V\)</span>-fold<a class="anchor" aria-label="anchor" href="#rolling-window-with-v-fold"><i class="fas fa-link"></i></a>
</h4>
<p>Just like the scheme described above, the rolling window approach, like the
rolling origin approach, can be extended to support multiple time-series with
arbitrary sample-level dependence by incorporating a <span class="math inline">\(V\)</span>-fold splitting
component. This rolling-window-<span class="math inline">\(V\)</span>-fold cross-validation scheme can be used
through <code>origami</code> via the <code>folds_vfold_rolling_window_pooled(n, t, id, time, V, window_size, validation_size, gap, batch)</code> function. The figure below displays
<span class="math inline">\(V=2\)</span> folds and two time-series (rolling window) cross-validation folds.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-4"></span>
<img src="img/png/rolling_window_v_fold.png" alt="Rolling window V-fold CV" width="80%"><p class="caption">
FIGURE 2.4: Rolling window V-fold CV
</p>
</div>
</div>
</div>
</div>
<div id="general-workflow-of-origami" class="section level2">
<h2>
<span class="header-section-number">2.6</span> General workflow of <code>origami</code><a class="anchor" aria-label="anchor" href="#general-workflow-of-origami"><i class="fas fa-link"></i></a>
</h2>
<p>Before we dive into more details, let’s take a moment to review some of the
basic functionality in the <code>origami</code> <code>R</code> package. The main workhorse function in
<code>origami</code> is <code><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate()</a></code>. To start off, the user must define the fold
structure and a function that operates on each fold (this <code>cv_fun()</code>, in
<code>origami</code>’s parlance, usually dictates how the candidate learning algorithm is
trained and its predictions validated).</p>
<p>Once passed to <code><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate()</a></code>, the workhorse function will iteratively apply
the specified function (i.e., <code>cv_fun()</code>) to each fold, combining the
fold-specific results in a meaningful way. We will see this in action in later
sections — for now, we provide specific details on each each step of this
process below.</p>
<div id="define-folds" class="section level3">
<h3>
<span class="header-section-number">2.6.1</span> (1) Define folds<a class="anchor" aria-label="anchor" href="#define-folds"><i class="fas fa-link"></i></a>
</h3>
<p>The <code>folds</code> object passed to <code>cross_validate</code> is a <code>list</code> of folds; such <code>list</code>
objects are generated using the <code><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds()</a></code> helper function. Each fold
consists of a <code>list</code> with a <code>"training"</code> index vector, a <code>"validation"</code> index
vector, and a <code>"fold_index"</code> (its order in the overall <code>list</code> of folds). The
<code><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds()</a></code> function supports a variety of cross-validation schemes,
described in the preceding section. The <code><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds()</a></code> function can also ensure
balance across levels of a given variable (through the <code>strata_ids</code> arguments),
and it can also keep all observations on the same independent unit together (via
the <code>cluster_ids</code> argument).</p>
</div>
<div id="define-the-fold-function" class="section level3">
<h3>
<span class="header-section-number">2.6.2</span> (2) Define the fold function<a class="anchor" aria-label="anchor" href="#define-the-fold-function"><i class="fas fa-link"></i></a>
</h3>
<p>The <code>cv_fun</code> argument to <code><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate()</a></code> is a custom function that performs
some operation on each fold (again, <em>usually</em> this specifies the training of the
candidate learning algorithm and its evaluation on a given training/validation
split, i.e., in a single fold). The first argument to this function is the
<code>fold</code>, which specifies the indices of the units in a given training/validation
split (note that this first argument is automatically passed to the <code>cv_fun()</code>
by <code><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate()</a></code>, which queries the folds object from <code><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds()</a></code> in
doing so). Additional arguments can be passed to the <code>cv_fun()</code> through the
<code>...</code> argument to <code><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate()</a></code>. Within this function, the convenience
functions <code><a href="http://tlverse.org/origami/reference/fold_helpers.html">training()</a></code>, <code><a href="http://tlverse.org/origami/reference/fold_helpers.html">validation()</a></code> and <code><a href="http://tlverse.org/origami/reference/fold_helpers.html">fold_index()</a></code> can be used to return
the various components of a fold object. When the <code><a href="http://tlverse.org/origami/reference/fold_helpers.html">training()</a></code> or
<code><a href="http://tlverse.org/origami/reference/fold_helpers.html">validation()</a></code> functions are passed an object of a particular class, they will
index that object in a sensible way. For instance, if the input object is a
vector, these helper functions will index the vector directly, but if the input
object is a <code>data.frame</code> or <code>matrix</code>, these functions will automatically index
the rows. This allows the user to easily partition data into training and
validation sets. The fold function must return a named <code>list</code> of results
containing whatever fold-specific outputs are desired.</p>
</div>
<div id="apply-cross_validate" class="section level3">
<h3>
<span class="header-section-number">2.6.3</span> (3) Apply <code>cross_validate()</code><a class="anchor" aria-label="anchor" href="#apply-cross_validate"><i class="fas fa-link"></i></a>
</h3>
<p>After defining the folds, the <code><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate()</a></code> function can be used to map the
<code>cv_fun()</code> across the <code>folds</code>; internally, this uses either <code><a href="https://rdrr.io/r/base/lapply.html">lapply()</a></code> or
<code>future_lapply()</code> (a parallelized variant of the same). In this way,
<code><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate()</a></code> can be easily parallelized by specifying a parallelization
scheme (i.e., a <code>plan</code> from the <a href="https://Cran.R-project.org/package=future">future parallelization framework for
<code>R</code></a> <span class="citation">(Bengtsson <a href="references.html#ref-bengtsson2021unifying" role="doc-biblioref">2021</a>)</span>). The
application of <code><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate()</a></code> generates a list of results, matching the
customized <code>list</code> specified in the relevant <code>cv_fun()</code>. As noted above, each
call to <code>cv_fun()</code> itself returns a <code>list</code> of results, with different named
slots for each type of result we wish to store. The main <code><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate()</a></code>
loop generates a <code>list</code> of these individual, fold-specific <code>list</code>s of results (a
<code>list</code> of <code>list</code>s or “meta-list”). Internally, this “meta-list” is cleaned up
(by concatenation) such that only a single slot per type of result specified by
the <code>cv_fun()</code> is returned (this too is a <code>list</code> of the results for each fold).
By default, the <code><a href="http://tlverse.org/origami/reference/combine_results.html">combine_results()</a></code> helper function is used to combine the
individual, fold-specific <code>list</code>s of results in a sensible manner. How results
are combined is determined automatically by examining the data types of the
results from the first fold. This can be modified by specifying a <code>list</code> of
arguments in the <code>.combine_control</code> argument.</p>
</div>
</div>
<div id="cross-validation-in-action" class="section level2">
<h2>
<span class="header-section-number">2.7</span> Cross-validation in action<a class="anchor" aria-label="anchor" href="#cross-validation-in-action"><i class="fas fa-link"></i></a>
</h2>
<p>We’ve waited long enough. Now, let’s see <code>origami</code> in action! In the next
chapter, we will learn how to use cross-validation with the Super Learner
algorithm, and how we can utilize the power of cross-validation to build optimal
ensembles of algorithms — going far beyond the application of cross-validation
to a single statistical learning method.</p>
<div id="cross-validation-with-linear-regression" class="section level3">
<h3>
<span class="header-section-number">2.7.1</span> Cross-validation with linear regression<a class="anchor" aria-label="anchor" href="#cross-validation-with-linear-regression"><i class="fas fa-link"></i></a>
</h3>
<p>First, let’s load the relevant <code>R</code> packages, set a seed (for reproducibility),
and once again load the WASH Benefits example dataset. For illustrative
purposes, we’ll examine the application of cross-validation to simple linear
regression with <code>origami</code>, focusing on predicting the weight-for-height Z-score
(<code>whz</code>) using all of the other available covariates in the dataset. As mentioned
before, we will assume the dataset contains only independent and identically
distributed units, ignoring the clustering structure imposed by the trial
design. For the sake of illustration, we will work with only a subset of the
data, removing all observational units with missing covariate data from the
analysis-ready dataset. In the prior chapter, we discussed how to deal with
missingness.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://stringr.tidyverse.org">stringr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyr.tidyverse.org">tidyr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># load data set and take a peek</span></span>
<span><span class="va">washb_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/fread.html">fread</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span></span>
<span>    <span class="st">"https://raw.githubusercontent.com/tlverse/tlverse-data/master/"</span>,</span>
<span>    <span class="st">"wash-benefits/washb_data.csv"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  stringsAsFactors <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># remove missing data with drop_na(), then pick just the first 500 rows</span></span>
<span><span class="va">washb_data</span> <span class="op">&lt;-</span> <span class="va">washb_data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://tidyr.tidyverse.org/reference/drop_na.html">drop_na</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/slice.html">slice</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">500</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># specify the outcome and covariates as character vectors</span></span>
<span><span class="va">outcome</span> <span class="op">&lt;-</span> <span class="st">"whz"</span></span>
<span><span class="va">covars</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="va">washb_data</span><span class="op">)</span> <span class="op">==</span> <span class="va">outcome</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<p>Here’s a look at the data:</p>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<div class="inline-table"><table class="table" style="margin-left: auto; margin-right: auto;">
<thead><tr>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
whz
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
tr
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fracode
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
month
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
aged
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
sex
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momage
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momedu
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momheight
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
hfiacat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Nlt18
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Ncomp
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
watmin
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
elec
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
floor
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
walls
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
roof
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_wardrobe
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_table
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chair
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_khat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chouki
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_tv
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_refrig
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_bike
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_moto
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_sewmach
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_mobile
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
268
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
146.40
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.16
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
286
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
148.75
</td>
<td style="text-align:left;">
Moderately Food Insecure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.05
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
264
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
152.15
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.26
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
252
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
28
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
140.25
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.59
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
336
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
150.95
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.51
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
304
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
154.20
</td>
<td style="text-align:left;">
Severely Food Insecure
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table></div>
</div>
<p>Let’s remind ourselves of the covariates to be used in the prediction step:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="origami.html#cb15-1"></a>covars</span>
<span id="cb15-2"><a href="origami.html#cb15-2"></a> [<span class="dv">1</span>] <span class="st">"tr"</span>             <span class="st">"fracode"</span>        <span class="st">"month"</span>          <span class="st">"aged"</span>          </span>
<span id="cb15-3"><a href="origami.html#cb15-3"></a> [<span class="dv">5</span>] <span class="st">"sex"</span>            <span class="st">"momage"</span>         <span class="st">"momedu"</span>         <span class="st">"momheight"</span>     </span>
<span id="cb15-4"><a href="origami.html#cb15-4"></a> [<span class="dv">9</span>] <span class="st">"hfiacat"</span>        <span class="st">"Nlt18"</span>          <span class="st">"Ncomp"</span>          <span class="st">"watmin"</span>        </span>
<span id="cb15-5"><a href="origami.html#cb15-5"></a>[<span class="dv">13</span>] <span class="st">"elec"</span>           <span class="st">"floor"</span>          <span class="st">"walls"</span>          <span class="st">"roof"</span>          </span>
<span id="cb15-6"><a href="origami.html#cb15-6"></a>[<span class="dv">17</span>] <span class="st">"asset_wardrobe"</span> <span class="st">"asset_table"</span>    <span class="st">"asset_chair"</span>    <span class="st">"asset_khat"</span>    </span>
<span id="cb15-7"><a href="origami.html#cb15-7"></a>[<span class="dv">21</span>] <span class="st">"asset_chouki"</span>   <span class="st">"asset_tv"</span>       <span class="st">"asset_refrig"</span>   <span class="st">"asset_bike"</span>    </span>
<span id="cb15-8"><a href="origami.html#cb15-8"></a>[<span class="dv">25</span>] <span class="st">"asset_moto"</span>     <span class="st">"asset_sewmach"</span>  <span class="st">"asset_mobile"</span>  </span></code></pre></div>
<p>Next, let’s fit a simple main-terms linear regression model to the
analysis-ready dataset. Here, our goal is to predict the weight-for-height
Z-score (<code>"whz"</code>, which we assigned to the variable <code>outcome</code>) using all of the
available covariate data. Let’s try it out:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="origami.html#cb16-1"></a>lm_mod &lt;-<span class="st"> </span><span class="kw">lm</span>(whz <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> washb_data)</span>
<span id="cb16-2"><a href="origami.html#cb16-2"></a><span class="kw">summary</span>(lm_mod)</span>
<span id="cb16-3"><a href="origami.html#cb16-3"></a></span>
<span id="cb16-4"><a href="origami.html#cb16-4"></a>Call<span class="op">:</span></span>
<span id="cb16-5"><a href="origami.html#cb16-5"></a><span class="kw">lm</span>(<span class="dt">formula =</span> whz <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> washb_data)</span>
<span id="cb16-6"><a href="origami.html#cb16-6"></a></span>
<span id="cb16-7"><a href="origami.html#cb16-7"></a>Residuals<span class="op">:</span></span>
<span id="cb16-8"><a href="origami.html#cb16-8"></a><span class="st">    </span>Min      1Q  Median      3Q     Max </span>
<span id="cb16-9"><a href="origami.html#cb16-9"></a><span class="fl">-2.8890</span> <span class="fl">-0.6799</span> <span class="fl">-0.0169</span>  <span class="fl">0.6595</span>  <span class="fl">3.1005</span> </span>
<span id="cb16-10"><a href="origami.html#cb16-10"></a></span>
<span id="cb16-11"><a href="origami.html#cb16-11"></a>Coefficients<span class="op">:</span></span>
<span id="cb16-12"><a href="origami.html#cb16-12"></a><span class="st">                                </span>Estimate Std. Error t value <span class="kw">Pr</span>(<span class="op">&gt;</span><span class="er">|</span>t<span class="op">|</span>)   </span>
<span id="cb16-13"><a href="origami.html#cb16-13"></a>(Intercept)                     <span class="fl">-1.89006</span>    <span class="fl">1.72022</span>   <span class="fl">-1.10</span>   <span class="fl">0.2725</span>   </span>
<span id="cb16-14"><a href="origami.html#cb16-14"></a>trHandwashing                   <span class="fl">-0.25276</span>    <span class="fl">0.17032</span>   <span class="fl">-1.48</span>   <span class="fl">0.1385</span>   </span>
<span id="cb16-15"><a href="origami.html#cb16-15"></a>trNutrition                     <span class="fl">-0.09695</span>    <span class="fl">0.15696</span>   <span class="fl">-0.62</span>   <span class="fl">0.5371</span>   </span>
<span id="cb16-16"><a href="origami.html#cb16-16"></a>trNutrition <span class="op">+</span><span class="st"> </span>WSH               <span class="fl">-0.09587</span>    <span class="fl">0.16528</span>   <span class="fl">-0.58</span>   <span class="fl">0.5622</span>   </span>
<span id="cb16-17"><a href="origami.html#cb16-17"></a>trSanitation                    <span class="fl">-0.27702</span>    <span class="fl">0.15846</span>   <span class="fl">-1.75</span>   <span class="fl">0.0811</span> . </span>
<span id="cb16-18"><a href="origami.html#cb16-18"></a>trWSH                           <span class="fl">-0.02846</span>    <span class="fl">0.15967</span>   <span class="fl">-0.18</span>   <span class="fl">0.8586</span>   </span>
<span id="cb16-19"><a href="origami.html#cb16-19"></a>trWater                         <span class="fl">-0.07148</span>    <span class="fl">0.15813</span>   <span class="fl">-0.45</span>   <span class="fl">0.6515</span>   </span>
<span id="cb16-20"><a href="origami.html#cb16-20"></a>fracodeN05160                    <span class="fl">0.62355</span>    <span class="fl">0.30719</span>    <span class="fl">2.03</span>   <span class="fl">0.0430</span> <span class="op">*</span><span class="st"> </span></span>
<span id="cb16-21"><a href="origami.html#cb16-21"></a>fracodeN05265                    <span class="fl">0.38762</span>    <span class="fl">0.31011</span>    <span class="fl">1.25</span>   <span class="fl">0.2120</span>   </span>
<span id="cb16-22"><a href="origami.html#cb16-22"></a>fracodeN05359                    <span class="fl">0.10187</span>    <span class="fl">0.31329</span>    <span class="fl">0.33</span>   <span class="fl">0.7452</span>   </span>
<span id="cb16-23"><a href="origami.html#cb16-23"></a>fracodeN06229                    <span class="fl">0.30933</span>    <span class="fl">0.29766</span>    <span class="fl">1.04</span>   <span class="fl">0.2993</span>   </span>
<span id="cb16-24"><a href="origami.html#cb16-24"></a>fracodeN06453                    <span class="fl">0.08066</span>    <span class="fl">0.30006</span>    <span class="fl">0.27</span>   <span class="fl">0.7882</span>   </span>
<span id="cb16-25"><a href="origami.html#cb16-25"></a>fracodeN06458                    <span class="fl">0.43707</span>    <span class="fl">0.29970</span>    <span class="fl">1.46</span>   <span class="fl">0.1454</span>   </span>
<span id="cb16-26"><a href="origami.html#cb16-26"></a>fracodeN06473                    <span class="fl">0.45406</span>    <span class="fl">0.30912</span>    <span class="fl">1.47</span>   <span class="fl">0.1426</span>   </span>
<span id="cb16-27"><a href="origami.html#cb16-27"></a>fracodeN06479                    <span class="fl">0.60994</span>    <span class="fl">0.31463</span>    <span class="fl">1.94</span>   <span class="fl">0.0532</span> . </span>
<span id="cb16-28"><a href="origami.html#cb16-28"></a>fracodeN06489                    <span class="fl">0.25923</span>    <span class="fl">0.31901</span>    <span class="fl">0.81</span>   <span class="fl">0.4169</span>   </span>
<span id="cb16-29"><a href="origami.html#cb16-29"></a>fracodeN06500                    <span class="fl">0.07539</span>    <span class="fl">0.35794</span>    <span class="fl">0.21</span>   <span class="fl">0.8333</span>   </span>
<span id="cb16-30"><a href="origami.html#cb16-30"></a>fracodeN06502                    <span class="fl">0.36748</span>    <span class="fl">0.30504</span>    <span class="fl">1.20</span>   <span class="fl">0.2290</span>   </span>
<span id="cb16-31"><a href="origami.html#cb16-31"></a>fracodeN06505                    <span class="fl">0.20038</span>    <span class="fl">0.31560</span>    <span class="fl">0.63</span>   <span class="fl">0.5258</span>   </span>
<span id="cb16-32"><a href="origami.html#cb16-32"></a>fracodeN06516                    <span class="fl">0.55455</span>    <span class="fl">0.29807</span>    <span class="fl">1.86</span>   <span class="fl">0.0635</span> . </span>
<span id="cb16-33"><a href="origami.html#cb16-33"></a>fracodeN06524                    <span class="fl">0.49429</span>    <span class="fl">0.31423</span>    <span class="fl">1.57</span>   <span class="fl">0.1164</span>   </span>
<span id="cb16-34"><a href="origami.html#cb16-34"></a>fracodeN06528                    <span class="fl">0.75966</span>    <span class="fl">0.31060</span>    <span class="fl">2.45</span>   <span class="fl">0.0148</span> <span class="op">*</span><span class="st"> </span></span>
<span id="cb16-35"><a href="origami.html#cb16-35"></a>fracodeN06531                    <span class="fl">0.36856</span>    <span class="fl">0.30155</span>    <span class="fl">1.22</span>   <span class="fl">0.2223</span>   </span>
<span id="cb16-36"><a href="origami.html#cb16-36"></a>fracodeN06862                    <span class="fl">0.56932</span>    <span class="fl">0.29293</span>    <span class="fl">1.94</span>   <span class="fl">0.0526</span> . </span>
<span id="cb16-37"><a href="origami.html#cb16-37"></a>fracodeN08002                    <span class="fl">0.36779</span>    <span class="fl">0.26846</span>    <span class="fl">1.37</span>   <span class="fl">0.1714</span>   </span>
<span id="cb16-38"><a href="origami.html#cb16-38"></a>month                            <span class="fl">0.17161</span>    <span class="fl">0.10865</span>    <span class="fl">1.58</span>   <span class="fl">0.1149</span>   </span>
<span id="cb16-39"><a href="origami.html#cb16-39"></a>aged                            <span class="fl">-0.00336</span>    <span class="fl">0.00112</span>   <span class="fl">-3.00</span>   <span class="fl">0.0029</span> <span class="op">**</span></span>
<span id="cb16-40"><a href="origami.html#cb16-40"></a>sexmale                          <span class="fl">0.12352</span>    <span class="fl">0.09203</span>    <span class="fl">1.34</span>   <span class="fl">0.1802</span>   </span>
<span id="cb16-41"><a href="origami.html#cb16-41"></a>momage                          <span class="fl">-0.01379</span>    <span class="fl">0.00973</span>   <span class="fl">-1.42</span>   <span class="fl">0.1570</span>   </span>
<span id="cb16-42"><a href="origami.html#cb16-42"></a><span class="kw">momeduPrimary</span> (<span class="dv">1</span><span class="op">-</span>5y)            <span class="fl">-0.13214</span>    <span class="fl">0.15225</span>   <span class="fl">-0.87</span>   <span class="fl">0.3859</span>   </span>
<span id="cb16-43"><a href="origami.html#cb16-43"></a><span class="kw">momeduSecondary</span> (<span class="op">&gt;</span>5y)            <span class="fl">0.12632</span>    <span class="fl">0.16041</span>    <span class="fl">0.79</span>   <span class="fl">0.4314</span>   </span>
<span id="cb16-44"><a href="origami.html#cb16-44"></a>momheight                        <span class="fl">0.00512</span>    <span class="fl">0.00919</span>    <span class="fl">0.56</span>   <span class="fl">0.5776</span>   </span>
<span id="cb16-45"><a href="origami.html#cb16-45"></a>hfiacatMildly Food Insecure      <span class="fl">0.05804</span>    <span class="fl">0.19341</span>    <span class="fl">0.30</span>   <span class="fl">0.7643</span>   </span>
<span id="cb16-46"><a href="origami.html#cb16-46"></a>hfiacatModerately Food Insecure <span class="fl">-0.01362</span>    <span class="fl">0.12887</span>   <span class="fl">-0.11</span>   <span class="fl">0.9159</span>   </span>
<span id="cb16-47"><a href="origami.html#cb16-47"></a>hfiacatSeverely Food Insecure   <span class="fl">-0.13447</span>    <span class="fl">0.25418</span>   <span class="fl">-0.53</span>   <span class="fl">0.5970</span>   </span>
<span id="cb16-48"><a href="origami.html#cb16-48"></a>Nlt18                           <span class="fl">-0.02557</span>    <span class="fl">0.04060</span>   <span class="fl">-0.63</span>   <span class="fl">0.5291</span>   </span>
<span id="cb16-49"><a href="origami.html#cb16-49"></a>Ncomp                            <span class="fl">0.00179</span>    <span class="fl">0.00762</span>    <span class="fl">0.23</span>   <span class="fl">0.8145</span>   </span>
<span id="cb16-50"><a href="origami.html#cb16-50"></a>watmin                           <span class="fl">0.01347</span>    <span class="fl">0.00861</span>    <span class="fl">1.57</span>   <span class="fl">0.1182</span>   </span>
<span id="cb16-51"><a href="origami.html#cb16-51"></a>elec                             <span class="fl">0.08906</span>    <span class="fl">0.10700</span>    <span class="fl">0.83</span>   <span class="fl">0.4057</span>   </span>
<span id="cb16-52"><a href="origami.html#cb16-52"></a>floor                           <span class="fl">-0.17763</span>    <span class="fl">0.17734</span>   <span class="fl">-1.00</span>   <span class="fl">0.3171</span>   </span>
<span id="cb16-53"><a href="origami.html#cb16-53"></a>walls                           <span class="fl">-0.03001</span>    <span class="fl">0.21445</span>   <span class="fl">-0.14</span>   <span class="fl">0.8888</span>   </span>
<span id="cb16-54"><a href="origami.html#cb16-54"></a>roof                            <span class="fl">-0.03716</span>    <span class="fl">0.49214</span>   <span class="fl">-0.08</span>   <span class="fl">0.9399</span>   </span>
<span id="cb16-55"><a href="origami.html#cb16-55"></a>asset_wardrobe                  <span class="fl">-0.05754</span>    <span class="fl">0.13736</span>   <span class="fl">-0.42</span>   <span class="fl">0.6755</span>   </span>
<span id="cb16-56"><a href="origami.html#cb16-56"></a>asset_table                     <span class="fl">-0.22079</span>    <span class="fl">0.12276</span>   <span class="fl">-1.80</span>   <span class="fl">0.0728</span> . </span>
<span id="cb16-57"><a href="origami.html#cb16-57"></a>asset_chair                      <span class="fl">0.28012</span>    <span class="fl">0.13750</span>    <span class="fl">2.04</span>   <span class="fl">0.0422</span> <span class="op">*</span><span class="st"> </span></span>
<span id="cb16-58"><a href="origami.html#cb16-58"></a>asset_khat                       <span class="fl">0.02306</span>    <span class="fl">0.11766</span>    <span class="fl">0.20</span>   <span class="fl">0.8447</span>   </span>
<span id="cb16-59"><a href="origami.html#cb16-59"></a>asset_chouki                    <span class="fl">-0.13943</span>    <span class="fl">0.14084</span>   <span class="fl">-0.99</span>   <span class="fl">0.3227</span>   </span>
<span id="cb16-60"><a href="origami.html#cb16-60"></a>asset_tv                         <span class="fl">0.17723</span>    <span class="fl">0.12972</span>    <span class="fl">1.37</span>   <span class="fl">0.1726</span>   </span>
<span id="cb16-61"><a href="origami.html#cb16-61"></a>asset_refrig                     <span class="fl">0.12613</span>    <span class="fl">0.23162</span>    <span class="fl">0.54</span>   <span class="fl">0.5863</span>   </span>
<span id="cb16-62"><a href="origami.html#cb16-62"></a>asset_bike                      <span class="fl">-0.02568</span>    <span class="fl">0.10083</span>   <span class="fl">-0.25</span>   <span class="fl">0.7990</span>   </span>
<span id="cb16-63"><a href="origami.html#cb16-63"></a>asset_moto                      <span class="fl">-0.32094</span>    <span class="fl">0.19944</span>   <span class="fl">-1.61</span>   <span class="fl">0.1083</span>   </span>
<span id="cb16-64"><a href="origami.html#cb16-64"></a>asset_sewmach                    <span class="fl">0.05090</span>    <span class="fl">0.17795</span>    <span class="fl">0.29</span>   <span class="fl">0.7750</span>   </span>
<span id="cb16-65"><a href="origami.html#cb16-65"></a>asset_mobile                     <span class="fl">0.01420</span>    <span class="fl">0.14972</span>    <span class="fl">0.09</span>   <span class="fl">0.9245</span>   </span>
<span id="cb16-66"><a href="origami.html#cb16-66"></a><span class="op">---</span></span>
<span id="cb16-67"><a href="origami.html#cb16-67"></a>Signif. codes<span class="op">:</span><span class="st">  </span><span class="dv">0</span> <span class="st">'***'</span> <span class="fl">0.001</span> <span class="st">'**'</span> <span class="fl">0.01</span> <span class="st">'*'</span> <span class="fl">0.05</span> <span class="st">'.'</span> <span class="fl">0.1</span> <span class="st">' '</span> <span class="dv">1</span></span>
<span id="cb16-68"><a href="origami.html#cb16-68"></a></span>
<span id="cb16-69"><a href="origami.html#cb16-69"></a>Residual standard error<span class="op">:</span><span class="st"> </span><span class="fl">0.984</span> on <span class="dv">447</span> degrees of freedom</span>
<span id="cb16-70"><a href="origami.html#cb16-70"></a>Multiple R<span class="op">-</span>squared<span class="op">:</span><span class="st">  </span><span class="fl">0.129</span>, Adjusted R<span class="op">-</span>squared<span class="op">:</span><span class="st">  </span><span class="fl">0.0277</span> </span>
<span id="cb16-71"><a href="origami.html#cb16-71"></a>F<span class="op">-</span>statistic<span class="op">:</span><span class="st"> </span><span class="fl">1.27</span> on <span class="dv">52</span> and <span class="dv">447</span> DF,  p<span class="op">-</span>value<span class="op">:</span><span class="st"> </span><span class="fl">0.104</span></span></code></pre></div>
<p>We can assess the quality of the model fit on the dataset by comparing the
linear model’s predictions of the weight-for-height Z-score against the
observations of the same in the dataset. This is the well-known, and standard,
mean squared error (MSE). We can extract this summary measure from the <code>lm</code>
model object like so</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="origami.html#cb17-1"></a>(err &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">resid</span>(lm_mod)<span class="op">^</span><span class="dv">2</span>))</span>
<span id="cb17-2"><a href="origami.html#cb17-2"></a>[<span class="dv">1</span>] <span class="fl">0.86568</span></span></code></pre></div>
<p>The MSE estimate is 0.86568, which, from examination of the above, is merely the
mean of the squared residuals of the model fit. An important problem arises
when we assess the learning algorithm’s quality in this way — that is, because
we have trained our linear regression model on the complete analysis-ready
dataset and then assessed its performance (the MSE) on the same dataset, all of
the data is used for both model training and validation. Unfortunately, this
simple estimate of the MSE is overly optimistic. Why? The linear regression
model is trained on the same dataset used in its evaluation, not unlike reusing
problems from a homework assignment in a course examination. Of course, we are
generally not interested in how well the algorithm explains variation in the
observed dataset; rather, we are interested in how well the explanations
provided by the learning algorithm generalize to a target population from which
this particular sample is drawn. By using all of the data available to us for
training the learning algorithm, we are left unable to honestly evaluate how
well the algorithm fits (and, thus, explains) variation at the level of the
target population.
<!--
RP: 
suggestion to make the above paragraph more concise
-->
To resolve this issue, cross-validation allows for a particular procedure (e.g.,
linear regression) to be implemented over training and validation splits of the
dataset, evaluating how well the procedure fits on a holdout (or validation)
set. This evaluation of the learning algorithm’s quality on data unseen during
the training phase provides an honest evaluation of the algorithm’s
generalization error.</p>
<p>We can easily incorporate cross-validation into our linear regression procedure
using <code>origami</code>. First, let’s define a new function to perform linear regression
on a specific partition of the dataset (i.e., a fold):</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cv_lm</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">fold</span>, <span class="va">data</span>, <span class="va">reg_form</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># get name and index of outcome variable from regression formula</span></span>
<span>  <span class="va">out_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_split.html">str_split</a></span><span class="op">(</span><span class="va">reg_form</span>, <span class="st">" "</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">out_var_ind</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">==</span> <span class="va">out_var</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># split up data into training and validation sets</span></span>
<span>  <span class="va">train_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">training</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span>  <span class="va">valid_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">validation</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># fit linear model on training set and predict on validation set</span></span>
<span>  <span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/formula.html">as.formula</a></span><span class="op">(</span><span class="va">reg_form</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">train_data</span><span class="op">)</span></span>
<span>  <span class="va">preds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">valid_data</span><span class="op">)</span></span>
<span>  <span class="va">valid_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">valid_data</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># capture results to be returned as output</span></span>
<span>  <span class="va">out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>    coef <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">mod</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    SE <span class="op">=</span> <span class="op">(</span><span class="va">preds</span> <span class="op">-</span> <span class="va">valid_data</span><span class="op">[</span>, <span class="va">out_var_ind</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">out</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>Our <code>cv_lm()</code> function is quite simple: It merely splits the available data into
distinct training and validation sets (using the eponymous functions provided in
<code>origami</code>), fits the linear model on the training set, and evaluates the quality
of the trained linear regression model on the validation set. This is a simple
example of what <code>origami</code> considers to be a <code>cv_fun()</code> — functions for applying
a particular routine over an input dataset in cross-validated manner.</p>
<p>Having defined such a function, we can simply generate a set of partitions using
<code>origami</code>’s <code><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds()</a></code> function and apply our <code>cv_lm()</code> function over the
resultant <code>folds</code> object using <code><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate()</a></code>. Below, we replicate the
re-substitution estimate of the error — we did this “by hand” above — using the
functions <code><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds()</a></code> and <code>cv_lm()</code>.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="origami.html#cb19-1"></a><span class="co"># re-substitution estimate</span></span>
<span id="cb19-2"><a href="origami.html#cb19-2"></a>resub &lt;-<span class="st"> </span><span class="kw">make_folds</span>(washb_data, <span class="dt">fold_fun =</span> folds_resubstitution)[[<span class="dv">1</span>]]</span>
<span id="cb19-3"><a href="origami.html#cb19-3"></a>resub_results &lt;-<span class="st"> </span><span class="kw">cv_lm</span>(<span class="dt">fold =</span> resub, <span class="dt">data =</span> washb_data, <span class="dt">reg_form =</span> <span class="st">"whz ~ ."</span>)</span>
<span id="cb19-4"><a href="origami.html#cb19-4"></a><span class="kw">mean</span>(resub_results<span class="op">$</span>SE, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</span>
<span id="cb19-5"><a href="origami.html#cb19-5"></a>[<span class="dv">1</span>] <span class="fl">0.86568</span></span></code></pre></div>
<p>This (nearly) matches the estimate of the error that we obtained above.</p>
<p>We can more honestly evaluate the error by <span class="math inline">\(V\)</span>-fold cross-validation, which
partitions the dataset into <span class="math inline">\(V\)</span> subsets, fitting the algorithm on <span class="math inline">\(V - 1\)</span> of the
subsets (training) and evaluating on the subset that was held out from
fitting (validation). This is repeated such that each holdout subset
takes a turn being used for validation. We can easily apply our <code>cv_lm()</code>
function in this way using <code>origami</code>’s <code><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate()</a></code> (note that by default
this function performs <span class="math inline">\(10\)</span>-fold cross-validation):</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="origami.html#cb20-1"></a><span class="co"># cross-validated estimate</span></span>
<span id="cb20-2"><a href="origami.html#cb20-2"></a>folds &lt;-<span class="st"> </span><span class="kw">make_folds</span>(washb_data)</span>
<span id="cb20-3"><a href="origami.html#cb20-3"></a>cvlm_results &lt;-<span class="st"> </span><span class="kw">cross_validate</span>(</span>
<span id="cb20-4"><a href="origami.html#cb20-4"></a>  <span class="dt">cv_fun =</span> cv_lm, <span class="dt">folds =</span> folds, <span class="dt">data =</span> washb_data, <span class="dt">reg_form =</span> <span class="st">"whz ~ ."</span>,</span>
<span id="cb20-5"><a href="origami.html#cb20-5"></a>  <span class="dt">use_future =</span> <span class="ot">FALSE</span></span>
<span id="cb20-6"><a href="origami.html#cb20-6"></a>)</span>
<span id="cb20-7"><a href="origami.html#cb20-7"></a><span class="kw">mean</span>(cvlm_results<span class="op">$</span>SE, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</span>
<span id="cb20-8"><a href="origami.html#cb20-8"></a>[<span class="dv">1</span>] <span class="fl">1.35</span></span></code></pre></div>
<p>Having performed <span class="math inline">\(V\)</span>-fold cross-validation with 10 folds (the default), we
quickly notice that our previous
estimate of the model error (by re-substitution) was a bit optimistic. The honest
estimate of the linear regression model’s error is larger!</p>
</div>
<div id="cross-validation-with-random-forests" class="section level3">
<h3>
<span class="header-section-number">2.7.2</span> Cross-validation with random forests<a class="anchor" aria-label="anchor" href="#cross-validation-with-random-forests"><i class="fas fa-link"></i></a>
</h3>
<p>To examine <code>origami</code> further, let’s return to our example analysis using the
WASH Benefits dataset. Here, we will write a new <code>cv_fun()</code> function. As an
example, we will use Breiman’s random forest algorithm <span class="citation">(Breiman <a href="references.html#ref-breiman2001random" role="doc-biblioref">2001</a>)</span>,
implemented in the <code><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest()</a></code> function (from the <code>randomForest</code> package):</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># make sure to load the package!</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://www.stat.berkeley.edu/~breiman/RandomForests/">randomForest</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">cv_rf</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">fold</span>, <span class="va">data</span>, <span class="va">reg_form</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="co"># get name and index of outcome variable from regression formula</span></span>
<span>  <span class="va">out_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/character.html">as.character</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="fu"><a href="https://stringr.tidyverse.org/reference/str_split.html">str_split</a></span><span class="op">(</span><span class="va">reg_form</span>, <span class="st">" "</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">out_var_ind</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span> <span class="op">==</span> <span class="va">out_var</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># define training and validation sets based on input object of class "folds"</span></span>
<span>  <span class="va">train_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">training</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span>  <span class="va">valid_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="http://tlverse.org/origami/reference/fold_helpers.html">validation</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># fit Random Forest regression on training set and predict on holdout set</span></span>
<span>  <span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html">as.formula</a></span><span class="op">(</span><span class="va">reg_form</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">train_data</span><span class="op">)</span></span>
<span>  <span class="va">preds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mod</span>, newdata <span class="op">=</span> <span class="va">valid_data</span><span class="op">)</span></span>
<span>  <span class="va">valid_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">valid_data</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># define output object to be returned as list (for flexibility)</span></span>
<span>  <span class="va">out</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span></span>
<span>    coef <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">mod</span><span class="op">$</span><span class="va">coefs</span><span class="op">)</span>,</span>
<span>    SE <span class="op">=</span> <span class="op">(</span><span class="op">(</span><span class="va">preds</span> <span class="op">-</span> <span class="va">valid_data</span><span class="op">[</span>, <span class="va">out_var_ind</span><span class="op">]</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">out</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>The <code>cv_rf()</code> function, which cross-validates the training and evaluation of the
<code>randomForest</code> algorithm, used our previous <code>cv_lm()</code> function as a template.
For now, individual <code>cv_fun()</code>s must be written by hand; however, in future
releases of the package, a wrapper may be made available to support
auto-generating <code>cv_fun</code>s for use with <code>origami</code>.</p>
<p>Below, we use <code><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate()</a></code> to apply our custom <code>cv_rf()</code> function over the
<code>folds</code> object generated by <code><a href="http://tlverse.org/origami/reference/make_folds.html">make_folds()</a></code>:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="origami.html#cb22-1"></a><span class="co"># now, let's cross-validate...</span></span>
<span id="cb22-2"><a href="origami.html#cb22-2"></a>folds &lt;-<span class="st"> </span><span class="kw">make_folds</span>(washb_data)</span>
<span id="cb22-3"><a href="origami.html#cb22-3"></a>cvrf_results &lt;-<span class="st"> </span><span class="kw">cross_validate</span>(</span>
<span id="cb22-4"><a href="origami.html#cb22-4"></a>  <span class="dt">cv_fun =</span> cv_rf, <span class="dt">folds =</span> folds,</span>
<span id="cb22-5"><a href="origami.html#cb22-5"></a>  <span class="dt">data =</span> washb_data, <span class="dt">reg_form =</span> <span class="st">"whz ~ ."</span>,</span>
<span id="cb22-6"><a href="origami.html#cb22-6"></a>  <span class="dt">use_future =</span> <span class="ot">FALSE</span></span>
<span id="cb22-7"><a href="origami.html#cb22-7"></a>)</span>
<span id="cb22-8"><a href="origami.html#cb22-8"></a><span class="kw">mean</span>(cvrf_results<span class="op">$</span>SE)</span>
<span id="cb22-9"><a href="origami.html#cb22-9"></a>[<span class="dv">1</span>] <span class="fl">1.0271</span></span></code></pre></div>
<p>Using <span class="math inline">\(V\)</span>-fold cross-validation with 10 folds, we obtain an honest estimate of
the prediction error of this random forest. This is one example of how
<code>origami</code>’s <code><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate()</a></code> procedure can be generalized to arbitrary
estimation techniques, as long as an appropriate <code>cv_fun()</code> function is
available.</p>
</div>
<div id="cross-validation-with-arima" class="section level3">
<h3>
<span class="header-section-number">2.7.3</span> Cross-validation with ARIMA<a class="anchor" aria-label="anchor" href="#cross-validation-with-arima"><i class="fas fa-link"></i></a>
</h3>
<p>Cross-validation can also be used for the selection of forecasting models in
settings with time-series data. Here, the partitioning scheme mirrors the
application of the forecasting model: We’ll train the learning algorithm on past
observations (either all available or a recent, in time, subset), and then use
the fitted model to predict the next (again, in time) few observations. To
demonstrate this, we return to the <code>AirPassengers</code> dataset, a monthly
time-series of passenger air traffic for thousands of travelers.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="origami.html#cb23-1"></a><span class="kw">data</span>(AirPassengers)</span>
<span id="cb23-2"><a href="origami.html#cb23-2"></a><span class="kw">print</span>(AirPassengers)</span>
<span id="cb23-3"><a href="origami.html#cb23-3"></a>     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec</span>
<span id="cb23-4"><a href="origami.html#cb23-4"></a><span class="dv">1949</span> <span class="dv">112</span> <span class="dv">118</span> <span class="dv">132</span> <span class="dv">129</span> <span class="dv">121</span> <span class="dv">135</span> <span class="dv">148</span> <span class="dv">148</span> <span class="dv">136</span> <span class="dv">119</span> <span class="dv">104</span> <span class="dv">118</span></span>
<span id="cb23-5"><a href="origami.html#cb23-5"></a><span class="dv">1950</span> <span class="dv">115</span> <span class="dv">126</span> <span class="dv">141</span> <span class="dv">135</span> <span class="dv">125</span> <span class="dv">149</span> <span class="dv">170</span> <span class="dv">170</span> <span class="dv">158</span> <span class="dv">133</span> <span class="dv">114</span> <span class="dv">140</span></span>
<span id="cb23-6"><a href="origami.html#cb23-6"></a><span class="dv">1951</span> <span class="dv">145</span> <span class="dv">150</span> <span class="dv">178</span> <span class="dv">163</span> <span class="dv">172</span> <span class="dv">178</span> <span class="dv">199</span> <span class="dv">199</span> <span class="dv">184</span> <span class="dv">162</span> <span class="dv">146</span> <span class="dv">166</span></span>
<span id="cb23-7"><a href="origami.html#cb23-7"></a><span class="dv">1952</span> <span class="dv">171</span> <span class="dv">180</span> <span class="dv">193</span> <span class="dv">181</span> <span class="dv">183</span> <span class="dv">218</span> <span class="dv">230</span> <span class="dv">242</span> <span class="dv">209</span> <span class="dv">191</span> <span class="dv">172</span> <span class="dv">194</span></span>
<span id="cb23-8"><a href="origami.html#cb23-8"></a><span class="dv">1953</span> <span class="dv">196</span> <span class="dv">196</span> <span class="dv">236</span> <span class="dv">235</span> <span class="dv">229</span> <span class="dv">243</span> <span class="dv">264</span> <span class="dv">272</span> <span class="dv">237</span> <span class="dv">211</span> <span class="dv">180</span> <span class="dv">201</span></span>
<span id="cb23-9"><a href="origami.html#cb23-9"></a><span class="dv">1954</span> <span class="dv">204</span> <span class="dv">188</span> <span class="dv">235</span> <span class="dv">227</span> <span class="dv">234</span> <span class="dv">264</span> <span class="dv">302</span> <span class="dv">293</span> <span class="dv">259</span> <span class="dv">229</span> <span class="dv">203</span> <span class="dv">229</span></span>
<span id="cb23-10"><a href="origami.html#cb23-10"></a><span class="dv">1955</span> <span class="dv">242</span> <span class="dv">233</span> <span class="dv">267</span> <span class="dv">269</span> <span class="dv">270</span> <span class="dv">315</span> <span class="dv">364</span> <span class="dv">347</span> <span class="dv">312</span> <span class="dv">274</span> <span class="dv">237</span> <span class="dv">278</span></span>
<span id="cb23-11"><a href="origami.html#cb23-11"></a><span class="dv">1956</span> <span class="dv">284</span> <span class="dv">277</span> <span class="dv">317</span> <span class="dv">313</span> <span class="dv">318</span> <span class="dv">374</span> <span class="dv">413</span> <span class="dv">405</span> <span class="dv">355</span> <span class="dv">306</span> <span class="dv">271</span> <span class="dv">306</span></span>
<span id="cb23-12"><a href="origami.html#cb23-12"></a><span class="dv">1957</span> <span class="dv">315</span> <span class="dv">301</span> <span class="dv">356</span> <span class="dv">348</span> <span class="dv">355</span> <span class="dv">422</span> <span class="dv">465</span> <span class="dv">467</span> <span class="dv">404</span> <span class="dv">347</span> <span class="dv">305</span> <span class="dv">336</span></span>
<span id="cb23-13"><a href="origami.html#cb23-13"></a><span class="dv">1958</span> <span class="dv">340</span> <span class="dv">318</span> <span class="dv">362</span> <span class="dv">348</span> <span class="dv">363</span> <span class="dv">435</span> <span class="dv">491</span> <span class="dv">505</span> <span class="dv">404</span> <span class="dv">359</span> <span class="dv">310</span> <span class="dv">337</span></span>
<span id="cb23-14"><a href="origami.html#cb23-14"></a><span class="dv">1959</span> <span class="dv">360</span> <span class="dv">342</span> <span class="dv">406</span> <span class="dv">396</span> <span class="dv">420</span> <span class="dv">472</span> <span class="dv">548</span> <span class="dv">559</span> <span class="dv">463</span> <span class="dv">407</span> <span class="dv">362</span> <span class="dv">405</span></span>
<span id="cb23-15"><a href="origami.html#cb23-15"></a><span class="dv">1960</span> <span class="dv">417</span> <span class="dv">391</span> <span class="dv">419</span> <span class="dv">461</span> <span class="dv">472</span> <span class="dv">535</span> <span class="dv">622</span> <span class="dv">606</span> <span class="dv">508</span> <span class="dv">461</span> <span class="dv">390</span> <span class="dv">432</span></span></code></pre></div>
<p>Suppose we want to pick between two forecasting models with different ARIMA
(AutoRegressive Integrated Moving Average) model configurations. We can choose
among such models by evaluating their forecasting performance. First, we set up
an appropriate cross-validation scheme for use with time-series data. Here, we
pick the rolling origin cross-validation scheme described above.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="origami.html#cb24-1"></a>folds &lt;-<span class="st"> </span><span class="kw">make_folds</span>(AirPassengers,</span>
<span id="cb24-2"><a href="origami.html#cb24-2"></a>  <span class="dt">fold_fun =</span> folds_rolling_origin,</span>
<span id="cb24-3"><a href="origami.html#cb24-3"></a>  <span class="dt">first_window =</span> <span class="dv">36</span>, <span class="dt">validation_size =</span> <span class="dv">24</span>, <span class="dt">batch =</span> <span class="dv">10</span></span>
<span id="cb24-4"><a href="origami.html#cb24-4"></a>)</span>
<span id="cb24-5"><a href="origami.html#cb24-5"></a></span>
<span id="cb24-6"><a href="origami.html#cb24-6"></a><span class="co"># How many folds where generated?</span></span>
<span id="cb24-7"><a href="origami.html#cb24-7"></a><span class="kw">length</span>(folds)</span>
<span id="cb24-8"><a href="origami.html#cb24-8"></a>[<span class="dv">1</span>] <span class="dv">9</span></span>
<span id="cb24-9"><a href="origami.html#cb24-9"></a></span>
<span id="cb24-10"><a href="origami.html#cb24-10"></a><span class="co"># Examine the first 2 folds.</span></span>
<span id="cb24-11"><a href="origami.html#cb24-11"></a>folds[[<span class="dv">1</span>]]</span>
<span id="cb24-12"><a href="origami.html#cb24-12"></a><span class="op">$</span>v</span>
<span id="cb24-13"><a href="origami.html#cb24-13"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb24-14"><a href="origami.html#cb24-14"></a></span>
<span id="cb24-15"><a href="origami.html#cb24-15"></a><span class="op">$</span>training_set</span>
<span id="cb24-16"><a href="origami.html#cb24-16"></a> [<span class="dv">1</span>]  <span class="dv">1</span>  <span class="dv">2</span>  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">5</span>  <span class="dv">6</span>  <span class="dv">7</span>  <span class="dv">8</span>  <span class="dv">9</span> <span class="dv">10</span> <span class="dv">11</span> <span class="dv">12</span> <span class="dv">13</span> <span class="dv">14</span> <span class="dv">15</span> <span class="dv">16</span> <span class="dv">17</span> <span class="dv">18</span> <span class="dv">19</span> <span class="dv">20</span> <span class="dv">21</span> <span class="dv">22</span> <span class="dv">23</span> <span class="dv">24</span> <span class="dv">25</span></span>
<span id="cb24-17"><a href="origami.html#cb24-17"></a>[<span class="dv">26</span>] <span class="dv">26</span> <span class="dv">27</span> <span class="dv">28</span> <span class="dv">29</span> <span class="dv">30</span> <span class="dv">31</span> <span class="dv">32</span> <span class="dv">33</span> <span class="dv">34</span> <span class="dv">35</span> <span class="dv">36</span></span>
<span id="cb24-18"><a href="origami.html#cb24-18"></a></span>
<span id="cb24-19"><a href="origami.html#cb24-19"></a><span class="op">$</span>validation_set</span>
<span id="cb24-20"><a href="origami.html#cb24-20"></a> [<span class="dv">1</span>] <span class="dv">37</span> <span class="dv">38</span> <span class="dv">39</span> <span class="dv">40</span> <span class="dv">41</span> <span class="dv">42</span> <span class="dv">43</span> <span class="dv">44</span> <span class="dv">45</span> <span class="dv">46</span> <span class="dv">47</span> <span class="dv">48</span> <span class="dv">49</span> <span class="dv">50</span> <span class="dv">51</span> <span class="dv">52</span> <span class="dv">53</span> <span class="dv">54</span> <span class="dv">55</span> <span class="dv">56</span> <span class="dv">57</span> <span class="dv">58</span> <span class="dv">59</span> <span class="dv">60</span></span>
<span id="cb24-21"><a href="origami.html#cb24-21"></a></span>
<span id="cb24-22"><a href="origami.html#cb24-22"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb24-23"><a href="origami.html#cb24-23"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span>
<span id="cb24-24"><a href="origami.html#cb24-24"></a>folds[[<span class="dv">2</span>]]</span>
<span id="cb24-25"><a href="origami.html#cb24-25"></a><span class="op">$</span>v</span>
<span id="cb24-26"><a href="origami.html#cb24-26"></a>[<span class="dv">1</span>] <span class="dv">2</span></span>
<span id="cb24-27"><a href="origami.html#cb24-27"></a></span>
<span id="cb24-28"><a href="origami.html#cb24-28"></a><span class="op">$</span>training_set</span>
<span id="cb24-29"><a href="origami.html#cb24-29"></a> [<span class="dv">1</span>]  <span class="dv">1</span>  <span class="dv">2</span>  <span class="dv">3</span>  <span class="dv">4</span>  <span class="dv">5</span>  <span class="dv">6</span>  <span class="dv">7</span>  <span class="dv">8</span>  <span class="dv">9</span> <span class="dv">10</span> <span class="dv">11</span> <span class="dv">12</span> <span class="dv">13</span> <span class="dv">14</span> <span class="dv">15</span> <span class="dv">16</span> <span class="dv">17</span> <span class="dv">18</span> <span class="dv">19</span> <span class="dv">20</span> <span class="dv">21</span> <span class="dv">22</span> <span class="dv">23</span> <span class="dv">24</span> <span class="dv">25</span></span>
<span id="cb24-30"><a href="origami.html#cb24-30"></a>[<span class="dv">26</span>] <span class="dv">26</span> <span class="dv">27</span> <span class="dv">28</span> <span class="dv">29</span> <span class="dv">30</span> <span class="dv">31</span> <span class="dv">32</span> <span class="dv">33</span> <span class="dv">34</span> <span class="dv">35</span> <span class="dv">36</span> <span class="dv">37</span> <span class="dv">38</span> <span class="dv">39</span> <span class="dv">40</span> <span class="dv">41</span> <span class="dv">42</span> <span class="dv">43</span> <span class="dv">44</span> <span class="dv">45</span> <span class="dv">46</span></span>
<span id="cb24-31"><a href="origami.html#cb24-31"></a></span>
<span id="cb24-32"><a href="origami.html#cb24-32"></a><span class="op">$</span>validation_set</span>
<span id="cb24-33"><a href="origami.html#cb24-33"></a> [<span class="dv">1</span>] <span class="dv">47</span> <span class="dv">48</span> <span class="dv">49</span> <span class="dv">50</span> <span class="dv">51</span> <span class="dv">52</span> <span class="dv">53</span> <span class="dv">54</span> <span class="dv">55</span> <span class="dv">56</span> <span class="dv">57</span> <span class="dv">58</span> <span class="dv">59</span> <span class="dv">60</span> <span class="dv">61</span> <span class="dv">62</span> <span class="dv">63</span> <span class="dv">64</span> <span class="dv">65</span> <span class="dv">66</span> <span class="dv">67</span> <span class="dv">68</span> <span class="dv">69</span> <span class="dv">70</span></span>
<span id="cb24-34"><a href="origami.html#cb24-34"></a></span>
<span id="cb24-35"><a href="origami.html#cb24-35"></a><span class="kw">attr</span>(,<span class="st">"class"</span>)</span>
<span id="cb24-36"><a href="origami.html#cb24-36"></a>[<span class="dv">1</span>] <span class="st">"fold"</span></span></code></pre></div>
<p>By default, <code>folds_rolling_origin</code> will increase the size of the training set by
one time point in each training fold. Had we followed the default option, we
would have 85 folds to train! Luckily, we can pass the <code>batch</code> as an option to
<code>folds_rolling_origin</code>, telling it to increase the size of the training set by
10 points in each iteration (so that we don’t have so many training folds).
Since we want to forecast the immediately following time point, the <code>gap</code>
argument remains at its default of zero.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="origami.html#cb25-1"></a><span class="co"># make sure to load the package!</span></span>
<span id="cb25-2"><a href="origami.html#cb25-2"></a><span class="kw">library</span>(forecast)</span>
<span id="cb25-3"><a href="origami.html#cb25-3"></a></span>
<span id="cb25-4"><a href="origami.html#cb25-4"></a><span class="co"># function to calculate cross-validated squared error</span></span>
<span id="cb25-5"><a href="origami.html#cb25-5"></a>cv_forecasts &lt;-<span class="st"> </span><span class="cf">function</span>(fold, data) {</span>
<span id="cb25-6"><a href="origami.html#cb25-6"></a>  <span class="co"># Get training and validation data</span></span>
<span id="cb25-7"><a href="origami.html#cb25-7"></a>  train_data &lt;-<span class="st"> </span><span class="kw">training</span>(data)</span>
<span id="cb25-8"><a href="origami.html#cb25-8"></a>  valid_data &lt;-<span class="st"> </span><span class="kw">validation</span>(data)</span>
<span id="cb25-9"><a href="origami.html#cb25-9"></a>  valid_size &lt;-<span class="st"> </span><span class="kw">length</span>(valid_data)</span>
<span id="cb25-10"><a href="origami.html#cb25-10"></a></span>
<span id="cb25-11"><a href="origami.html#cb25-11"></a>  train_ts &lt;-<span class="st"> </span><span class="kw">ts</span>(<span class="kw">log10</span>(train_data), <span class="dt">frequency =</span> <span class="dv">12</span>)</span>
<span id="cb25-12"><a href="origami.html#cb25-12"></a></span>
<span id="cb25-13"><a href="origami.html#cb25-13"></a>  <span class="co"># First arima model</span></span>
<span id="cb25-14"><a href="origami.html#cb25-14"></a>  arima_fit &lt;-<span class="st"> </span><span class="kw">arima</span>(train_ts, <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb25-15"><a href="origami.html#cb25-15"></a>    <span class="dt">seasonal =</span> <span class="kw">list</span>(</span>
<span id="cb25-16"><a href="origami.html#cb25-16"></a>      <span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb25-17"><a href="origami.html#cb25-17"></a>      <span class="dt">period =</span> <span class="dv">12</span></span>
<span id="cb25-18"><a href="origami.html#cb25-18"></a>    )</span>
<span id="cb25-19"><a href="origami.html#cb25-19"></a>  )</span>
<span id="cb25-20"><a href="origami.html#cb25-20"></a>  raw_arima_pred &lt;-<span class="st"> </span><span class="kw">predict</span>(arima_fit, <span class="dt">n.ahead =</span> valid_size)</span>
<span id="cb25-21"><a href="origami.html#cb25-21"></a>  arima_pred &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span>raw_arima_pred<span class="op">$</span>pred</span>
<span id="cb25-22"><a href="origami.html#cb25-22"></a>  arima_MSE &lt;-<span class="st"> </span><span class="kw">mean</span>((arima_pred <span class="op">-</span><span class="st"> </span>valid_data)<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb25-23"><a href="origami.html#cb25-23"></a></span>
<span id="cb25-24"><a href="origami.html#cb25-24"></a>  <span class="co"># Second arima model</span></span>
<span id="cb25-25"><a href="origami.html#cb25-25"></a>  arima_fit2 &lt;-<span class="st"> </span><span class="kw">arima</span>(train_ts, <span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb25-26"><a href="origami.html#cb25-26"></a>    <span class="dt">seasonal =</span> <span class="kw">list</span>(</span>
<span id="cb25-27"><a href="origami.html#cb25-27"></a>      <span class="dt">order =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb25-28"><a href="origami.html#cb25-28"></a>      <span class="dt">period =</span> <span class="dv">12</span></span>
<span id="cb25-29"><a href="origami.html#cb25-29"></a>    )</span>
<span id="cb25-30"><a href="origami.html#cb25-30"></a>  )</span>
<span id="cb25-31"><a href="origami.html#cb25-31"></a>  raw_arima_pred2 &lt;-<span class="st"> </span><span class="kw">predict</span>(arima_fit2, <span class="dt">n.ahead =</span> valid_size)</span>
<span id="cb25-32"><a href="origami.html#cb25-32"></a>  arima_pred2 &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span>raw_arima_pred2<span class="op">$</span>pred</span>
<span id="cb25-33"><a href="origami.html#cb25-33"></a>  arima_MSE2 &lt;-<span class="st"> </span><span class="kw">mean</span>((arima_pred2 <span class="op">-</span><span class="st"> </span>valid_data)<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb25-34"><a href="origami.html#cb25-34"></a></span>
<span id="cb25-35"><a href="origami.html#cb25-35"></a>  out &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">mse =</span> <span class="kw">data.frame</span>(</span>
<span id="cb25-36"><a href="origami.html#cb25-36"></a>    <span class="dt">fold =</span> <span class="kw">fold_index</span>(),</span>
<span id="cb25-37"><a href="origami.html#cb25-37"></a>    <span class="dt">arima =</span> arima_MSE, <span class="dt">arima2 =</span> arima_MSE2</span>
<span id="cb25-38"><a href="origami.html#cb25-38"></a>  ))</span>
<span id="cb25-39"><a href="origami.html#cb25-39"></a>  <span class="kw">return</span>(out)</span>
<span id="cb25-40"><a href="origami.html#cb25-40"></a>}</span>
<span id="cb25-41"><a href="origami.html#cb25-41"></a></span>
<span id="cb25-42"><a href="origami.html#cb25-42"></a>mses &lt;-<span class="st"> </span><span class="kw">cross_validate</span>(</span>
<span id="cb25-43"><a href="origami.html#cb25-43"></a>  <span class="dt">cv_fun =</span> cv_forecasts, <span class="dt">folds =</span> folds, <span class="dt">data =</span> AirPassengers,</span>
<span id="cb25-44"><a href="origami.html#cb25-44"></a>  <span class="dt">use_future =</span> <span class="ot">FALSE</span></span>
<span id="cb25-45"><a href="origami.html#cb25-45"></a>)</span>
<span id="cb25-46"><a href="origami.html#cb25-46"></a>mses<span class="op">$</span>mse</span>
<span id="cb25-47"><a href="origami.html#cb25-47"></a>  fold   arima  arima2</span>
<span id="cb25-48"><a href="origami.html#cb25-48"></a><span class="dv">1</span>    <span class="dv">1</span>   <span class="fl">68.21</span>  <span class="fl">137.28</span></span>
<span id="cb25-49"><a href="origami.html#cb25-49"></a><span class="dv">2</span>    <span class="dv">2</span>  <span class="fl">319.68</span>  <span class="fl">313.15</span></span>
<span id="cb25-50"><a href="origami.html#cb25-50"></a><span class="dv">3</span>    <span class="dv">3</span>  <span class="fl">578.35</span>  <span class="fl">713.36</span></span>
<span id="cb25-51"><a href="origami.html#cb25-51"></a><span class="dv">4</span>    <span class="dv">4</span>  <span class="fl">428.69</span>  <span class="fl">505.31</span></span>
<span id="cb25-52"><a href="origami.html#cb25-52"></a><span class="dv">5</span>    <span class="dv">5</span>  <span class="fl">407.33</span>  <span class="fl">371.27</span></span>
<span id="cb25-53"><a href="origami.html#cb25-53"></a><span class="dv">6</span>    <span class="dv">6</span>  <span class="fl">281.82</span>  <span class="fl">250.99</span></span>
<span id="cb25-54"><a href="origami.html#cb25-54"></a><span class="dv">7</span>    <span class="dv">7</span>  <span class="fl">827.56</span>  <span class="fl">910.12</span></span>
<span id="cb25-55"><a href="origami.html#cb25-55"></a><span class="dv">8</span>    <span class="dv">8</span> <span class="fl">2099.59</span> <span class="fl">2213.15</span></span>
<span id="cb25-56"><a href="origami.html#cb25-56"></a><span class="dv">9</span>    <span class="dv">9</span>  <span class="fl">398.37</span>  <span class="fl">293.38</span></span>
<span id="cb25-57"><a href="origami.html#cb25-57"></a><span class="kw">colMeans</span>(mses<span class="op">$</span>mse[, <span class="kw">c</span>(<span class="st">"arima"</span>, <span class="st">"arima2"</span>)])</span>
<span id="cb25-58"><a href="origami.html#cb25-58"></a> arima arima2 </span>
<span id="cb25-59"><a href="origami.html#cb25-59"></a><span class="fl">601.07</span> <span class="fl">634.22</span> </span></code></pre></div>
<p>By applying <code><a href="http://tlverse.org/origami/reference/cross_validate.html">cross_validate()</a></code> with this <code>cv_forecasts()</code> custom function, we
find that the ARIMA model with no AR (autoregressive) component seems to be a
better fit for this dataset.</p>
</div>
</div>
<div id="exercises" class="section level2">
<h2>
<span class="header-section-number">2.8</span> Exercises<a class="anchor" aria-label="anchor" href="#exercises"><i class="fas fa-link"></i></a>
</h2>
<!--
RP:
Love this structure
-->
<div id="review-of-key-concepts" class="section level3">
<h3>
<span class="header-section-number">2.8.1</span> Review of Key Concepts<a class="anchor" aria-label="anchor" href="#review-of-key-concepts"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>Compare and contrast <span class="math inline">\(V\)</span>-fold cross-validation with re-substitution
cross-validation. What are some of the differences between the two methods?
How are they similar? Describe a scenario when you would use one over the
other.</p></li>
<li>
<p>What are the advantages and disadvantages of <span class="math inline">\(V\)</span>-fold cross-validation
relative to:</p>
<ol style="list-style-type: lower-alpha">
<li>holdout cross-validation?</li>
<li>leave-one-out cross-validation?</li>
</ol>
</li>
<li><p>Why is <span class="math inline">\(V\)</span>-fold cross-validation inappropriate for use with time-series data?</p></li>
<li><p>Would you use rolling window or rolling origin cross-validation for
non-stationary time-series? Why?
<!--
RP:
Not sure if reader will understand non-stationary time-series in Q4. 
Could rephrase to something along the lines of why you would use one or the 
other, or provide a definition in parenthesis
-->
### The Ideas in Action</p></li>
<li><p>Let <span class="math inline">\(Y\)</span> be a binary variable with <span class="math inline">\(P(Y=1 \mid W) = 0.01\)</span>, that is, a rare
outcome. What kind of cross-validation scheme should be used with this type
of outcome? How can we do this with the <code>origami</code> package?</p></li>
<li><p>Consider the WASH Benefits example dataset discussed in this chapter. How can
we incorporate cluster-level information into a cross-validation scheme? How
can we implement this strategy with the <code>origami</code> package?</p></li>
</ol>
</div>
<div id="advanced-topics" class="section level3">
<h3>
<span class="header-section-number">2.8.2</span> Advanced Topics<a class="anchor" aria-label="anchor" href="#advanced-topics"><i class="fas fa-link"></i></a>
</h3>
<!--
RP:
Holy shit these are hard :,) but good! idk, but want to know, the answer to Q2!
-->
<ol style="list-style-type: decimal">
<li><p>Think about a dataset with a spatial dependence structure, in which the
degree of dependence is known such that the groups formed by this dependence
structure are clear and where there are no spillover effects. What kind of
cross-validation scheme would be appropriate in this case?</p></li>
<li><p>Continuing from the previous problem, what kind of procedure, and
cross-validation scheme, can we use if the spatial dependence is not as
clearly defined as in assumptions made in the preceding problem?</p></li>
<li>
<p>Consider a classification problem with a large number of predictors and a
binary outcome. Your friendly neighborhood statistician proposes the
following analysis:</p>
<ol style="list-style-type: lower-alpha">
<li>First, screen the predictors, isolating only those covariates that are
strongly correlated with the (binary) outcome labels.</li>
<li>Next, train a learning algorithm using only this subset of covariates
that are highly correlated with the outcome.</li>
<li>Finally, use cross-validation to estimate the tuning parameters and the
performance of the learning algorithm.</li>
</ol>
<p>Is this application of cross-validation correct? Why or why not?</p>
</li>
</ol>
<!--
## Appendix

### Exercise solutions
-->
</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="example-dataset.html">Example Dataset</a></div>
<div class="next"><a href="sl3.html"><span class="header-section-number">3</span> Super Learning</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#origami"><span class="header-section-number">2</span> Cross-validation</a></li>
<li><a class="nav-link" href="#learning-objectives-1">Learning Objectives</a></li>
<li><a class="nav-link" href="#introduction-2"><span class="header-section-number">2.1</span> Introduction</a></li>
<li>
<a class="nav-link" href="#background"><span class="header-section-number">2.2</span> Background</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#introducing-cross-validation"><span class="header-section-number">2.2.1</span> Introducing: cross-validation</a></li></ul>
</li>
<li><a class="nav-link" href="#estimation-roadmap-how-does-it-all-fit-together"><span class="header-section-number">2.3</span> Estimation Roadmap: How does it all fit together?</a></li>
<li><a class="nav-link" href="#example-cross-validation-and-prediction"><span class="header-section-number">2.4</span> Example: Cross-validation and Prediction</a></li>
<li>
<a class="nav-link" href="#cross-validation-schemes-in-origami"><span class="header-section-number">2.5</span> Cross-validation schemes in origami</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#wash-benefits-study-example">WASH Benefits Study Example</a></li>
<li><a class="nav-link" href="#cross-validation-for-i.i.d.-data"><span class="header-section-number">2.5.1</span> Cross-validation for i.i.d. data</a></li>
<li><a class="nav-link" href="#cross-validation-for-time-series-data"><span class="header-section-number">2.5.2</span> Cross-validation for Time-series Data</a></li>
<li><a class="nav-link" href="#airpassenger-data-example">AirPassenger Data Example</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#general-workflow-of-origami"><span class="header-section-number">2.6</span> General workflow of origami</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#define-folds"><span class="header-section-number">2.6.1</span> (1) Define folds</a></li>
<li><a class="nav-link" href="#define-the-fold-function"><span class="header-section-number">2.6.2</span> (2) Define the fold function</a></li>
<li><a class="nav-link" href="#apply-cross_validate"><span class="header-section-number">2.6.3</span> (3) Apply cross_validate()</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#cross-validation-in-action"><span class="header-section-number">2.7</span> Cross-validation in action</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#cross-validation-with-linear-regression"><span class="header-section-number">2.7.1</span> Cross-validation with linear regression</a></li>
<li><a class="nav-link" href="#cross-validation-with-random-forests"><span class="header-section-number">2.7.2</span> Cross-validation with random forests</a></li>
<li><a class="nav-link" href="#cross-validation-with-arima"><span class="header-section-number">2.7.3</span> Cross-validation with ARIMA</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#exercises"><span class="header-section-number">2.8</span> Exercises</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#review-of-key-concepts"><span class="header-section-number">2.8.1</span> Review of Key Concepts</a></li>
<li><a class="nav-link" href="#advanced-topics"><span class="header-section-number">2.8.2</span> Advanced Topics</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/tlverse/enar2023-workshop/blob/master/06-origami.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/tlverse/enar2023-workshop/edit/master/06-origami.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>[ENAR 2023 Short Course] Targeted Learning in the <code>tlverse</code></strong>: Advanced Methods for Causal Machine Learning" was written by Mark van der Laan, Alan Hubbard, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips. It was last built on updated: March 07, 2023.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
